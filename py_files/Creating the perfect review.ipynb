{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to enhance a comment to encourage trending?\n",
    "\n",
    "1. Get a list of top 10 words in the trending bucket. \n",
    "2. User enters a comment.\n",
    "3. Comment is scored.\n",
    "4. Determine if any of the top 10 words are missing, and score by adding the words to the comment.\n",
    "5. Output the comment score, and what would be the comment if 'x' word is added.\n",
    "\n",
    "Could use word2vec to find similar words through cosine similarity.\n",
    "\n",
    "Process:\n",
    "1. User enters comment\n",
    "2. Tokenize comment\n",
    "3. Find the most similar word compared to the corpus of trending products. \n",
    "4. Generate additional comments with swapping out one word.\n",
    "5. Comments are transformed (count vector -> lda -> log)\n",
    "6. Comments are predicted (SMOTE -> XGB) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dill\n",
    "\n",
    "import re\n",
    "from nltk import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "MODELING_PATH = '../data/modeling/'\n",
    "PATH = '../data/amazon_reviews_us_Toys_v1_00.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(obj, obj_name):\n",
    "    f = MODELING_PATH + obj_name\n",
    "    dill.dump(obj, open(f, 'wb'))\n",
    "\n",
    "def load(obj_name):\n",
    "    f = MODELING_PATH + obj_name\n",
    "    return dill.load(open(f, 'rb'))\n",
    "\n",
    "from AmazonReviews import AmazonReviews\n",
    "\n",
    "ar = AmazonReviews()\n",
    "ar.load_data(PATH)\n",
    "ar.calc_trend_score()\n",
    "ar.create_observations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# enter a comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment = 'This toy is amazing! So much worth the bucks!!'\n",
    "\n",
    "def token_comment(comment):\n",
    "    tkpat = re.compile('\\\\b[a-z][a-z]+\\\\b')\n",
    "    comment_token = tkpat.findall(comment)\n",
    "    return [w for w in comment_token if w not in set(stopwords.words())]\n",
    "\n",
    "comment_tokenized = token_comment(comment)\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "print (nlp.vocab[u'dog'].similarity(nlp.vocab[u'dachshund']))\n",
    "\n",
    "def get_related(word):\n",
    "    # replace word.vocab with the set of words in the trending review corpus\n",
    "    filtered_words = [w for w in word.vocab if w.is_lower == word.is_lower and w.prob >= -15]\n",
    "#     similarity = sorted(filtered_words, key=lambda w: word.similarity(w), reverse=True)\n",
    "#     return similarity[:10]\n",
    "\n",
    "get_related(nlp.vocab[u'plane'])\n",
    "# print( [w.lower_ for w in get_related(nlp.vocab[u'plane'])])\n",
    "\n",
    "## need to get the corpus of all reviews which have trended\n",
    "review_corpus = ' '.join(ar.obs[ar.obs.trend == 1].review_body)\n",
    "\n",
    "review_corpus = token_comment(review_corpus) # takes a long time\n",
    "review_corpus[:10]\n",
    "\n",
    "review_corpus = set(review_corpus)\n",
    "save(review_corpus, 'review_corpus.pkl')\n",
    "\n",
    "review_vocab = [nlp.vocab[w] for w in review_corpus] # critical\n",
    "\n",
    "len(review_corpus)\n",
    "\n",
    "def most_similar(word, top=10):\n",
    "#     filtered_words = [w for w in review_vocab if w.is_lower == word.is_lower]\n",
    "#     similarity_scores = [word.similarity(w) for w in review_vocab]\n",
    "#     words = [w.orth_ for w in review_vocab]\n",
    "    by_similarity = sorted(review_vocab, key=lambda w: word.similarity(w), reverse=True)\n",
    "    return [w.orth_ for w in by_similarity[:top]]\n",
    "#     return pd.DataFrame(data={'word':words, 'score':similar_scores})\n",
    "\n",
    "# most_similar(nlp.vocab[u'plane'])\n",
    "# comment_tokenized\n",
    "\n",
    "comment_list = [comment]\n",
    "for t in comment_tokenized:\n",
    "    sim_words = most_similar(nlp.vocab[t])\n",
    "    for s in sim_words:\n",
    "        new_comment = comment.replace(t, s)\n",
    "        if new_comment != comment:\n",
    "            comment_list.append(comment.replace(t, s))\n",
    "comment_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on the new comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_transformer = load('doc_5t_transformer.pkl')\n",
    "classifier_model = load('final_model_smote_5t.pkl')\n",
    "\n",
    "comments_transformed = doc_transformer.transform(comment_list)\n",
    "\n",
    "comment_probs = classifier_model.predict_proba(comments_transformed)[:,1]\n",
    "\n",
    "for c, p in zip(comment_list, comment_probs):\n",
    "    print(p, c)\n",
    "\n",
    "comment_list[comment_probs.argmax()] # pretty fucking cool\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "model_pipe = Pipeline(\n",
    "    [\n",
    "        ('step1', doc_transformer),\n",
    "        ('step2', classifier_model)\n",
    "    ]\n",
    ") # need to train on whole model\n",
    "\n",
    "model_pipe.predict_proba(comment_list)[:,1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
