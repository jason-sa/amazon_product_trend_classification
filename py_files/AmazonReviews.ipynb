{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToDos\n",
    "\n",
    "* Review term frequency in major and minor classes\n",
    "* Pre-compute DTM and sampling for training data sets\n",
    "* LDA will take a long time...can I fit on something smaller and then partial fit\n",
    "* Figure out AWS\n",
    "* Use spaCy to transform documents into vectorized form. This will bypass count/tf-idf -> PCA/LDA pipeline\n",
    "\n",
    "\n",
    "## Fixed Data\n",
    "1. CountVectorizer\n",
    "2. tf-idf\n",
    "3. spaCy word embeddings\n",
    "4. Sampling\n",
    "\n",
    "Build out all of the above data structures, and then pickle the class. I can then reload the class to run the model pipelines with right training data sets. \n",
    "\n",
    "How do I maintain the test data?\n",
    "* Create models to transform the text later.\n",
    "* Transform and save the data\n",
    "\n",
    "\n",
    "### Pipelines\n",
    "1. Count/tf-idf -> PCA / LDA -> Supervised Learning\n",
    "  * stemming applied\n",
    "  * english words\n",
    "2. Word Embeddings -> Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T15:06:38.013439Z",
     "start_time": "2018-11-09T15:06:35.064997Z"
    }
   },
   "outputs": [],
   "source": [
    "import AmazonReviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T15:06:38.072650Z",
     "start_time": "2018-11-09T15:06:38.016438Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T05:58:30.442661Z",
     "start_time": "2018-11-09T05:57:35.777221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read from pickle...\n"
     ]
    }
   ],
   "source": [
    "ar = AmazonReviews.AmazonReviews()\n",
    "\n",
    "PATH = '../data/amazon_reviews_us_Toys_v1_00.tsv'\n",
    "ar.load_data(PATH)\n",
    "\n",
    "ar.calc_trend_score()\n",
    "\n",
    "ar.create_observations()\n",
    "\n",
    "# ar.create_train_test_split(train_reduction=.1)\n",
    "ar.create_train_test_split()\n",
    "# ar.dump_models()\n",
    "\n",
    "# ar = ar.load_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the distribution of the first review data. 1/1/2014 is the most popular. May need to move the cutoff date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2014-01-01    0.030230\n",
    "2014-01-02    0.029510\n",
    "2014-01-03    0.026328\n",
    "2014-01-04    0.016026\n",
    "2014-01-07    0.014318"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T05:58:30.503607Z",
     "start_time": "2018-11-09T05:58:30.445471Z"
    }
   },
   "outputs": [],
   "source": [
    "# ar.reviews_selected_df.min_review_date.value_counts(normalize=True).sort_values(ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T05:58:30.556423Z",
     "start_time": "2018-11-09T05:58:30.506376Z"
    }
   },
   "outputs": [],
   "source": [
    "# ar.product_trend_df[ar.product_trend_df.trend == 1].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DTM / Sampling Creation\n",
    "\n",
    "Create DTM and only restrict features to English words in the `nltk.corpus.words`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T21:29:38.776613Z",
     "start_time": "2018-11-09T21:29:38.718154Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import words, stopwords\n",
    "from nltk import SnowballStemmer\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from imblearn.pipeline import Pipeline as imbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "\n",
    "# from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score, precision_score, accuracy_score\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# skf = StratifiedKFold(n_splits = 3, random_state=ar.RANDOM_STATE)\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "def english_corpus(doc, tkpat=re.compile('\\\\b[a-z][a-z]+\\\\b')):\n",
    "    return [stemmer.stem(w) for w in tkpat.findall(doc) if w not in ['br', 've']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T06:01:39.861608Z",
     "start_time": "2018-11-09T05:58:30.785888Z"
    }
   },
   "outputs": [],
   "source": [
    "## Create each pipe and add it to the data dictionary.\n",
    "pre_process_pipe = imbPipeline([\n",
    "                          ('cnt_v', CountVectorizer(\n",
    "                                        stop_words='english', \n",
    "                                        tokenizer=english_corpus, \n",
    "                                        min_df=2)),\n",
    "                          ('sm', SMOTE(random_state=42, n_jobs=-1))]) \n",
    "\n",
    "ar.pre_process_data(pre_process_pipe, 'cnt_v_1_gram_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T06:01:39.918868Z",
     "start_time": "2018-11-09T06:01:39.865122Z"
    }
   },
   "outputs": [],
   "source": [
    "first_pipe = imbPipeline([\n",
    "                          ('lda', LatentDirichletAllocation(         # could I fit on 1 of the 10 folds, and then partial fit\n",
    "                                        n_jobs=-1, \n",
    "                                        learning_method='online',    \n",
    "                                        random_state=42)),\n",
    "                          ('log_transform', FunctionTransformer(np.log)),\n",
    "                          ('ss', StandardScaler()),\n",
    "                          ('log_reg', LogisticRegression(random_state=42))])\n",
    "\n",
    "params = {\n",
    "    'lda__n_components': Integer(5, 20),\n",
    "    'lda__learning_decay': Real(0.5, 1),\n",
    "    'log_reg__C': Categorical([0.001,0.01,0.1,1,10,100])\n",
    "}\n",
    "\n",
    "grid = BayesSearchCV(first_pipe, params, n_jobs=-1, n_iter=20, cv=skf, scoring='precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T06:07:10.634887Z",
     "start_time": "2018-11-09T06:01:39.921666Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    }
   ],
   "source": [
    "ar.run_model(grid, 'mvp', 'cnt_v_1_gram_sm',sample=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T06:07:10.864252Z",
     "start_time": "2018-11-09T06:07:10.637890Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mvp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.229066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.009297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.682008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score</th>\n",
       "      <td>0.018344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.453120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                mvp\n",
       "Accuracy   0.229066\n",
       "Precision  0.009297\n",
       "Recall     0.682008\n",
       "F1 Score   0.018344\n",
       "AUC        0.453120"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T06:07:11.292156Z",
     "start_time": "2018-11-09T06:07:10.871230Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ar.conf_matrix('mvp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T06:09:21.814331Z",
     "start_time": "2018-11-09T06:09:00.551837Z"
    }
   },
   "outputs": [],
   "source": [
    "ar.dump_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of MVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T15:07:30.975581Z",
     "start_time": "2018-11-09T15:07:19.496857Z"
    }
   },
   "outputs": [],
   "source": [
    "ar = AmazonReviews.AmazonReviews()\n",
    "ar = ar.load_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T16:00:50.747155Z",
     "start_time": "2018-11-09T16:00:50.672970Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cnt_v_1_gram_sm', 'cnt_v_2_gram_sm', 'tf_idf_1_gram_sm'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar.pre_process_models.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T15:18:17.594280Z",
     "start_time": "2018-11-09T15:08:08.689067Z"
    }
   },
   "outputs": [],
   "source": [
    "pre_process_pipe = imbPipeline([\n",
    "                          ('cnt_v', CountVectorizer(\n",
    "                                        stop_words='english', \n",
    "                                        tokenizer=english_corpus, \n",
    "                                        min_df=2,\n",
    "                                        ngram_range = (1,2))),\n",
    "                          ('sm', SMOTE(random_state=42, n_jobs=-1))]) \n",
    "\n",
    "ar.pre_process_data(pre_process_pipe, 'cnt_v_2_gram_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T15:27:10.304866Z",
     "start_time": "2018-11-09T15:18:17.597330Z"
    }
   },
   "outputs": [],
   "source": [
    "pre_process_pipe = imbPipeline([\n",
    "                          ('cnt_v', TfidfVectorizer(\n",
    "                                        stop_words='english', \n",
    "                                        tokenizer=english_corpus, \n",
    "                                        min_df=2)),\n",
    "                          ('sm', SMOTE(random_state=42, n_jobs=-1))]) \n",
    "\n",
    "ar.pre_process_data(pre_process_pipe, 'tf_idf_1_gram_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T16:08:02.234847Z",
     "start_time": "2018-11-09T16:00:58.366230Z"
    }
   },
   "outputs": [],
   "source": [
    "pre_process_pipe = imbPipeline([\n",
    "                          ('cnt_v', TfidfVectorizer(\n",
    "                                        stop_words='english', \n",
    "                                        tokenizer=english_corpus, \n",
    "                                        min_df=2,\n",
    "                                        ngram_range = (1,2))),\n",
    "                          ('sm', SMOTE(random_state=42, n_jobs=-1))]) \n",
    "\n",
    "ar.pre_process_data(pre_process_pipe, 'tf_idf_2_gram_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T16:10:18.363674Z",
     "start_time": "2018-11-09T16:09:53.595652Z"
    }
   },
   "outputs": [],
   "source": [
    "ar.dump_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing complete\n",
    "\n",
    "DTMs using single and bi-grams generate with `CountVectorizer` and `TfidfVectorizer` with `SMOTE` upsampling. These transformations can now be fed into a pipeline with deminesion reduction and a classification algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizer EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T21:33:48.220444Z",
     "start_time": "2018-11-09T21:33:48.023755Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158400, 3421)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T19:58:25.070314Z",
     "start_time": "2018-11-09T19:58:24.995746Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158400,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar.X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T21:31:33.287361Z",
     "start_time": "2018-11-09T21:29:45.061720Z"
    }
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(\n",
    "                     stop_words=set(stopwords.words()), \n",
    "                        tokenizer=english_corpus, \n",
    "                        min_df=100,\n",
    "                        max_df=0.2,\n",
    "                        ngram_range = (1,2)) \n",
    "          \n",
    "\n",
    "tf = cv.fit_transform(ar.X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_df = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T20:02:15.688078Z",
     "start_time": "2018-11-09T20:02:15.131082Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['love', 'great', 'veri', 'like', 'good', 'just', 'look', 'littl',\n",
       "       'old', 'use', 'year', 'play', 'time', 'qualiti', 'realli', 'work',\n",
       "       'nice', 'perfect', 'bought', 'br', 'son', 'product', 'cute', 'fun',\n",
       "       'kid', 'toy', 'year old', 'daughter', 'onli', 'price', 'make',\n",
       "       'got', 'buy', 'gift', 'purchas', 'set', 'want', 'becaus',\n",
       "       'recommend', 'small', 'expect', 'piec', 'size', 'color', 'come',\n",
       "       'fit', 'game', 'don', 'item', 'need', 'came', 'br br', 'easi',\n",
       "       'thing', 'figur', 'lot', 'order', 'thank', 'happi', 'did',\n",
       "       'grandson', 'ani', 'box', 'card', 'way', 'pictur', 'togeth', 'day',\n",
       "       'awesom', 'arriv', 'better', 'pretti', 'think', 'big', 'high',\n",
       "       'ship', 'didn', 'collect', 'receiv', 'birthday', 'doll', 'enjoy',\n",
       "       'doe', 'say', 'christma', 'bit', 'plastic', 'disappoint', 'fast',\n",
       "       'worth', 'right', 'excel', 'thought', 'new', 'differ', 'hard',\n",
       "       'packag', 'money', 'doesn', 'tri'], dtype='<U55')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = np.array(cv.get_feature_names())\n",
    "counts = np.array(tf.sum(0))[0,:]\n",
    "vocab[np.argsort(-counts)[:100]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "max_df = 0.2, min_df = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T21:48:30.652133Z",
     "start_time": "2018-11-09T21:48:30.497791Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['great', 'veri', 'one', 'like', 'good', 'look', 'use', 'would',\n",
       "       'get', 'play', 'littl', 'well', 'old', 'year', 'time', 'realli',\n",
       "       'toy', 'game', 'work', 'qualiti', 'nice', 'product', 'kid',\n",
       "       'perfect', 'fun', 'bought', 'make', 'cute', 'set', 'onli',\n",
       "       'year old', 'daughter', 'made', 'price', 'got', 'piec', 'buy',\n",
       "       'much', 'figur', 'gift', 'card', 'purchas', 'becaus', 'put',\n",
       "       'even', 'small', 'color', 'size', 'go', 'expect', 'recommend',\n",
       "       'fit', 'item', 'doll', 'need', 'box', 'thing', 'order', 'still',\n",
       "       'lot', 'easi', 'came', 'two', 'puzzl', 'togeth', 'ani', 'happi',\n",
       "       'back', 'first', 'pictur', 'thank', 'could', 'way', 'grandson',\n",
       "       'day', 'think', 'pretti', 'better', 'part', 'big', 'take',\n",
       "       'awesom', 'collect', 'arriv', 'ship', 'receiv', 'high', 'detail',\n",
       "       'car', 'plastic', 'birthday', 'doe', 'say', 'bit', 'see', 'enjoy',\n",
       "       'right', 'differ', 'around', 'christma'], dtype='<U20')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = np.array(cv.get_feature_names())\n",
    "counts = np.array(tf.sum(0))[0,:]\n",
    "vocab[np.argsort(-counts)[:100]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T20:47:15.375960Z",
     "start_time": "2018-11-09T20:47:15.303368Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 129,  299, 2461, ...,  124,  188,  151], dtype=int64)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T20:17:57.965022Z",
     "start_time": "2018-11-09T20:17:57.912617Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3110"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_['ve']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T20:18:51.092096Z",
     "start_time": "2018-11-09T20:18:50.830913Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Not worth   bucks!!!!! This toy feels really cheap, the plastic is very light feeling (kind of like the imitation &# ;hot wheels&# ; cars you get at the dollar store). After only   day of play the figure became loose. When my son tries to transform it the pieces won't stay in place. Also the figure is very small about   or   inches. The only positive thing I can say about this is the metallic paint is really nice.\"]\n"
     ]
    }
   ],
   "source": [
    "t_word = ar.X_train[ar.X_train.str.contains('ve ')].head(1)\n",
    "print(t_word.values)\n",
    "# for w in [0].split():\n",
    "#     print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T21:43:03.432900Z",
     "start_time": "2018-11-09T21:33:59.749639Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=256, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.6,\n",
       "             learning_method='online', learning_offset=1024,\n",
       "             max_doc_update_iter=100, max_iter=10, mean_change_tol=0.001,\n",
       "             n_components=5, n_jobs=-1, n_topics=None, perp_tol=0.1,\n",
       "             random_state=None, topic_word_prior=0.005,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_components = 5\n",
    "\n",
    "lda = LatentDirichletAllocation(learning_method='online',\n",
    "                                learning_decay=0.6,\n",
    "                                batch_size=256,\n",
    "                                learning_offset=1024,\n",
    "                                n_components=n_components,\n",
    "                                n_jobs=-1,\n",
    "                                topic_word_prior=0.005,)\n",
    "\n",
    "lda.fit(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T22:52:53.932489Z",
     "start_time": "2018-11-09T22:52:19.179318Z"
    }
   },
   "outputs": [],
   "source": [
    "lda_tf = lda.transform(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T22:53:03.104704Z",
     "start_time": "2018-11-09T22:53:02.968421Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158400, 5)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T22:53:23.040519Z",
     "start_time": "2018-11-09T22:53:22.983414Z"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T23:15:21.459421Z",
     "start_time": "2018-11-09T23:15:20.337748Z"
    }
   },
   "outputs": [],
   "source": [
    "sm = SMOTE()\n",
    "X_train_smote, y_train_smote = sm.fit_sample(lda_tf, ar.y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T23:16:37.221071Z",
     "start_time": "2018-11-09T23:16:37.140538Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(313454, 5)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_smote.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T23:17:17.054156Z",
     "start_time": "2018-11-09T23:16:59.836190Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-10T00:02:07.230126Z",
     "start_time": "2018-11-10T00:02:04.320995Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.best_estimator_.predict(lda_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T23:11:48.366646Z",
     "start_time": "2018-11-09T23:11:48.314339Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score, confusion_matrix, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-10T00:20:56.898069Z",
     "start_time": "2018-11-10T00:20:54.289838Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7584120244936818\n",
      "0.0821199767035527\n",
      "0.04372262490794217\n",
      "[[132056  24671]\n",
      " [   545   1128]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.best_estimator_.predict(lda_tf)\n",
    "print(roc_auc_score(ar.y_train, y_pred))\n",
    "print(f1_score(ar.y_train, y_pred))\n",
    "print(precision_score(ar.y_train, y_pred))\n",
    "print(confusion_matrix(ar.y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Added a log transform to the probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-10T00:30:21.862970Z",
     "start_time": "2018-11-10T00:30:18.929788Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8210689786971472\n",
      "0.11479523254771931\n",
      "0.06204892225720513\n",
      "[[137363  19364]\n",
      " [   392   1281]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.best_estimator_.predict(lda_tf)\n",
    "print(roc_auc_score(ar.y_train, y_pred))\n",
    "print(f1_score(ar.y_train, y_pred))\n",
    "print(precision_score(ar.y_train, y_pred))\n",
    "print(confusion_matrix(ar.y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is with bi-grams and 5 topics with SMOTE. Could look at the following,\n",
    "\n",
    "* tri-grams or single-grams or only bi-grams\n",
    "* tweak max/min df\n",
    "* Increasing the components for LDA.\n",
    "* Build a spaCy document vector matrix (a new notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-10T00:30:04.087758Z",
     "start_time": "2018-11-10T00:24:13.729221Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BayesSearchCV(cv=3, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('log_transform', FunctionTransformer(accept_sparse=False, func=<ufunc 'log'>, inv_kw_args=None,\n",
       "          inverse_func=None, kw_args=None, pass_y='deprecated',\n",
       "          validate=True)), ('xgb', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, g...tate=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1))]),\n",
       "       fit_params=None, iid=True, n_iter=4, n_jobs=-1, n_points=1,\n",
       "       optimizer_kwargs=None, pre_dispatch='2*n_jobs', random_state=None,\n",
       "       refit=True, return_train_score=False, scoring='precision',\n",
       "       search_spaces={'xgb__n_estimators': Integer(low=100, high=500), 'xgb__learning_rate': Real(low=0, high=1, prior='uniform', transform='identity'), 'xgb__max_depth': Integer(low=2, high=5)},\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def on_step(optim_result):\n",
    "    score = grid.best_score_\n",
    "    print(f'best score: {score:.3}')\n",
    "#     if score >= 0.98:\n",
    "#         print('Interrupting!') # could stop it early if you hit some goal\n",
    "#         return True\n",
    "\n",
    "xgb_pipeline = Pipeline([\n",
    "        ('log_transform', FunctionTransformer(np.log)),\n",
    "        ('xgb', XGBClassifier(n_jobs=-1))]\n",
    ")\n",
    "\n",
    "xgb_params = {\n",
    "    'xgb__n_estimators': Integer(100, 500),\n",
    "    'xgb__learning_rate': Real(0,1),\n",
    "    'xgb__max_depth': Integer(2, 5)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "grid = BayesSearchCV(xgb_pipeline, xgb_params, cv=3, n_jobs=-1, scoring='precision', n_iter=4)\n",
    "grid.fit(X_train_smote, y_train_smote, callback=on_step) # add callback to print the score of each BayesSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "* Do NOT tf-idf if using LDA\n",
    "* tf-idf could be helpful for NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T21:48:37.662812Z",
     "start_time": "2018-11-09T21:48:37.603028Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOPIC 0\n",
      "great\n",
      "good\n",
      "veri\n",
      "qualiti\n",
      "product\n",
      "price\n",
      "work\n",
      "item\n",
      "ship\n",
      "thank\n",
      "\n",
      "TOPIC 1\n",
      "one\n",
      "would\n",
      "get\n",
      "piec\n",
      "like\n",
      "put\n",
      "use\n",
      "onli\n",
      "puzzl\n",
      "becaus\n",
      "\n",
      "TOPIC 2\n",
      "veri\n",
      "look\n",
      "cute\n",
      "nice\n",
      "well\n",
      "like\n",
      "figur\n",
      "doll\n",
      "great\n",
      "littl\n",
      "\n",
      "TOPIC 3\n",
      "old\n",
      "year\n",
      "play\n",
      "year old\n",
      "great\n",
      "fun\n",
      "gift\n",
      "daughter\n",
      "kid\n",
      "bought\n",
      "\n",
      "TOPIC 4\n",
      "card\n",
      "game\n",
      "one\n",
      "use\n",
      "get\n",
      "onli\n",
      "make\n",
      "set\n",
      "like\n",
      "model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for topic in range(n_components):\n",
    "    print(f\"TOPIC {topic}\")\n",
    "    for j in np.argsort(-lda.components_,1)[topic,:10]:\n",
    "        print(vocab[j])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T20:44:41.958025Z",
     "start_time": "2018-11-09T20:44:41.689147Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T20:48:52.309920Z",
     "start_time": "2018-11-09T20:48:52.218538Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw = set(stopwords.words())\n",
    "'just' in sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T21:47:58.456586Z",
     "start_time": "2018-11-09T21:47:26.979035Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/pyLDAvis/_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el6541137298428967441197014\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el6541137298428967441197014_data = {\"mdsDat\": {\"x\": [0.12409173573479083, 0.11988456455501077, 0.14904884372308144, -0.02579662196360934, -0.3672285220492737], \"y\": [-0.11715751495007112, -0.15974254480684394, 0.3116233309119967, -0.07471337001773366, 0.039990098862652305], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [32.88461413576631, 22.74288765117264, 17.018973903153427, 16.290978167482926, 11.062546142424688]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"Freq\": [36214.0, 33386.0, 20861.0, 15170.0, 14892.0, 12224.0, 12599.0, 11134.0, 16900.0, 10872.0, 18933.0, 12437.0, 9161.0, 13204.0, 11858.0, 10543.0, 11879.0, 9785.0, 7378.0, 7223.0, 8841.0, 10875.0, 13066.0, 5157.0, 10096.0, 5925.0, 16301.0, 10735.0, 5731.0, 23306.0, 8225.841262707147, 6352.706614263289, 6007.448950416486, 2440.9168366148187, 2266.5436421890076, 2113.127681491135, 2113.05533742482, 2073.5552645134057, 2021.756720208149, 1881.3796023430268, 1854.674455107695, 2033.1125974965937, 1812.7767480134028, 1990.0669937616158, 1069.60116583421, 1067.7932497191464, 993.6654668056522, 988.245802795647, 987.0396445657352, 1007.0023692344249, 946.475182489195, 921.751619976895, 969.5198303657492, 862.9438697054189, 851.3056799519936, 779.5288131998466, 750.8926481221389, 738.5374346697179, 732.3991183094141, 711.5875648655308, 10093.286716062566, 1679.305234398632, 960.924461091415, 2284.8146356245484, 1277.9737275274742, 4722.43875976784, 3538.2033514576992, 2653.392140957973, 3440.202672613202, 2672.623129529066, 11301.371034759562, 10999.437949207118, 2074.077406755143, 2806.9600592817633, 15407.473849642336, 6071.904282128724, 5071.790705309366, 3706.826066254501, 3194.4308886985227, 6574.524588770087, 3539.4138266401883, 8055.994090874704, 9681.107621626785, 3912.561738845875, 4634.0322195387125, 4832.588592508014, 3895.3977851506884, 5659.237399641908, 3001.9741659523183, 5759.534176859234, 3510.774781425124, 4260.5571603002245, 4663.826276137822, 4376.712898473384, 4969.102562435794, 3022.8876192138478, 4693.948841196964, 5775.219370894977, 3928.8336778859407, 3961.158909861189, 3813.899268990073, 3761.8267434780682, 8841.399125532675, 3628.133656188819, 2228.093109022259, 1819.2584219389596, 1816.4317952097492, 1609.5536237768467, 1256.8418498990027, 1244.7920052751463, 1154.0185559349777, 1088.3794786186338, 1052.5922411096808, 988.9097372142268, 935.2534971497009, 855.6586978599995, 851.2459576077955, 828.777048760499, 818.5173684309884, 806.4490850312128, 801.7438027246799, 740.425789379862, 720.1744822851724, 694.2184090081935, 688.4265056575955, 673.0882527630272, 666.9229369591392, 652.2772321006242, 637.5169356259128, 611.4903799025267, 605.6731132324294, 605.5953051776696, 4007.625024497947, 707.303004757988, 746.0501313479382, 2008.28094718091, 1534.4689474385102, 2321.5683832053905, 1989.6426732845123, 8680.398629468556, 3280.6357024926897, 1383.4107592523305, 2418.513839304089, 1372.3827263595003, 1911.9530793105355, 2905.4579386052696, 3945.7284289887552, 1304.3909691023587, 2442.804963064209, 3876.1087406537963, 3432.738287286143, 4515.462800737173, 4493.71831926453, 4413.720676135895, 5749.42258716773, 6887.398498753469, 2682.4371257763682, 2696.6430107862097, 4840.158395852849, 2308.885645240079, 1869.9223388248586, 4252.395358407189, 3982.3760831633663, 2537.3762519936217, 2391.674614048232, 2290.138714626552, 3034.287474723112, 2782.7764898262635, 2387.3160772369743, 2229.3412334240743, 10872.955693414036, 9161.267507944896, 5731.240462693846, 4946.272473077633, 4278.034179688006, 3928.256370944871, 3435.9154417694267, 2614.4453692861816, 2173.5859180498173, 2043.3138027654968, 1656.3737306319897, 1635.9843749545273, 1604.857446405875, 1368.372305332991, 1262.6183764825003, 1186.249021337379, 1183.4607850044642, 1147.11395516255, 1131.4023967074436, 1037.6277371626718, 1021.9279145647531, 913.818344792733, 888.4019247700708, 820.674257037045, 805.9048426994465, 732.1654224625944, 713.2413592950141, 692.6165467110785, 683.85243483202, 659.4688319463685, 15155.853764112864, 4613.746696761398, 2162.3980279830284, 14491.90800444665, 935.4594294606567, 2827.1615464074894, 9511.248093519294, 12876.321698220067, 8596.246493915494, 1605.7999145014714, 8595.145742694263, 3497.337664409386, 2774.922878036044, 2099.463943879741, 6366.876752067014, 5883.290580653291, 6332.013065686889, 9827.353635106345, 2883.2683689817964, 4385.702760137516, 4301.619702130877, 3928.5707941501314, 3189.621990984076, 3020.4956272579016, 2744.5746411893097, 2184.2335677239726, 2197.768236437488, 7223.655956854584, 3299.695145512877, 3112.9073833930497, 2344.5932919752986, 2284.644312129364, 1934.900254707016, 1757.4506524244953, 1731.462816044892, 1453.1520754895903, 1315.798532829453, 1190.0382232627667, 1091.2050998374314, 974.9748824982179, 906.3493732184442, 866.3364860728035, 853.7496564395306, 797.6042194593914, 748.6436260160528, 740.9968021492907, 739.2231826228466, 686.0001583981397, 678.7181802659788, 678.3051955198422, 669.6035647575229, 636.6125927633376, 621.368797106207, 608.025678580471, 605.9005631085637, 591.1453904967876, 584.3405886431167, 11128.264390483837, 775.1437390743716, 793.9521760171391, 1824.5630275213298, 10426.937947117549, 8134.342111797162, 4261.8835530842625, 12901.996783076376, 3967.477133859069, 5740.583277625756, 2298.5947910684986, 2752.0422327569004, 1176.3453150692505, 9269.867924989685, 6536.30391394656, 2834.7147894156865, 4811.91551872324, 2306.2072179688344, 2084.3986614447927, 1830.8440050272884, 13974.672102604223, 8720.854150536243, 6589.691040910206, 5796.972027545824, 2427.728513052101, 3963.644601670085, 6805.889997899594, 4132.044591582272, 2482.347685828324, 2756.7135911378714, 2421.5902268767054, 2363.4449986408704, 2344.1488229730235, 4306.557317478257, 2538.0203827849364, 2497.774835008904, 2213.676824931888, 2186.3964997629287, 1867.3157157651492, 1743.7442252919068, 1535.545197377009, 1416.84467384172, 1402.2926758350943, 1360.2831459760844, 1331.5182244273208, 1265.269016516884, 1199.3881855654788, 1107.6974402122971, 1067.9445779600112, 963.7185817256654, 821.3372660693432, 750.2055520292672, 734.9075292873937, 714.9640526468883, 614.9634299404369, 583.5729962958673, 581.3636259066596, 569.4481984670034, 533.5889914171178, 530.1795521763316, 513.3753462761935, 510.2230151821366, 492.0576601916166, 4077.845505997555, 5109.392251749691, 2139.308954093222, 1091.8249063505607, 2140.381434303504, 916.1782312554499, 10751.496877910939, 10867.002538621015, 3817.2198394568222, 5092.208312098894, 5881.034224105102, 13754.763237795285, 7022.645613207959, 18633.34160788013, 4176.789612185517, 13306.15150067709, 1733.227607665484, 6222.282176942053, 1930.6734554395339, 4182.577192414593, 4098.447072325206, 2817.093536270408, 2379.4012657501544, 2249.882886987276, 3168.30677125262, 3041.5184794017873, 3444.665876666663, 2263.1642095062793, 2759.4869813228993, 2309.5829128368, 2196.6551306412], \"Term\": [\"great\", \"veri\", \"good\", \"old\", \"year\", \"product\", \"qualiti\", \"cute\", \"play\", \"year old\", \"look\", \"nice\", \"gift\", \"work\", \"fun\", \"price\", \"kid\", \"figur\", \"item\", \"doll\", \"card\", \"daughter\", \"game\", \"ship\", \"piec\", \"thank\", \"well\", \"made\", \"grandson\", \"like\", \"put\", \"puzzl\", \"togeth\", \"put togeth\", \"ball\", \"book\", \"broke\", \"fall\", \"stay\", \"break\", \"water\", \"away\", \"apart\", \"track\", \"lost\", \"thought would\", \"fill\", \"ago\", \"push\", \"button\", \"given\", \"rip\", \"air\", \"fell\", \"frustrat\", \"string\", \"bubbl\", \"floor\", \"onli thing\", \"smell\", \"piec\", \"broken\", \"wood\", \"return\", \"hole\", \"back\", \"tri\", \"easili\", \"disappoint\", \"someth\", \"would\", \"get\", \"took\", \"last\", \"one\", \"becaus\", \"thing\", \"plastic\", \"open\", \"onli\", \"car\", \"use\", \"like\", \"could\", \"go\", \"even\", \"first\", \"work\", \"enough\", \"time\", \"day\", \"small\", \"make\", \"buy\", \"toy\", \"hard\", \"littl\", \"veri\", \"bought\", \"realli\", \"made\", \"got\", \"card\", \"kit\", \"deck\", \"player\", \"black\", \"red\", \"damag\", \"gun\", \"green\", \"dice\", \"satisfi\", \"coin\", \"sleev\", \"art\", \"dark\", \"effect\", \"engin\", \"list\", \"ring\", \"tail\", \"protect\", \"mold\", \"band\", \"wife\", \"dragon\", \"yellow\", \"glow\", \"mode\", \"tile\", \"good condit\", \"model\", \"rule\", \"gear\", \"version\", \"blue\", \"includ\", \"board\", \"game\", \"paint\", \"point\", \"build\", \"white\", \"pack\", \"differ\", \"need\", \"base\", \"best\", \"color\", \"box\", \"onli\", \"make\", \"set\", \"use\", \"one\", \"awesom\", \"part\", \"get\", \"star\", \"condit\", \"like\", \"good\", \"two\", \"ani\", \"arriv\", \"look\", \"play\", \"realli\", \"becaus\", \"year old\", \"gift\", \"grandson\", \"birthday\", \"parti\", \"granddaught\", \"daughter love\", \"kid love\", \"grandson love\", \"old love\", \"granddaught love\", \"niec\", \"nephew\", \"love play\", \"grand\", \"birthday parti\", \"yr\", \"lot fun\", \"yr old\", \"old daughter\", \"cake\", \"old grandson\", \"great gift\", \"great toy\", \"christma gift\", \"love love\", \"much fun\", \"play game\", \"grand daughter\", \"perfect condit\", \"old\", \"christma\", \"famili\", \"year\", \"month old\", \"costum\", \"fun\", \"play\", \"daughter\", \"present\", \"kid\", \"enjoy\", \"friend\", \"boy\", \"bought\", \"perfect\", \"toy\", \"great\", \"arriv\", \"game\", \"littl\", \"time\", \"got\", \"set\", \"use\", \"girl\", \"lot\", \"doll\", \"well made\", \"soft\", \"veri nice\", \"veri cute\", \"train\", \"look great\", \"hair\", \"plush\", \"bear\", \"stuf\", \"outfit\", \"articul\", \"super cute\", \"hors\", \"action figur\", \"worth money\", \"fit perfect\", \"sculpt\", \"shoe\", \"great addit\", \"like pictur\", \"realli cute\", \"smaller expect\", \"american\", \"well worth\", \"thoma\", \"stuf anim\", \"worth price\", \"figurin\", \"cute\", \"realist\", \"transform\", \"dress\", \"nice\", \"figur\", \"collect\", \"look\", \"detail\", \"size\", \"look like\", \"fan\", \"cloth\", \"well\", \"made\", \"beauti\", \"fit\", \"ador\", \"smaller\", \"veri well\", \"veri\", \"like\", \"littl\", \"realli\", \"cool\", \"small\", \"great\", \"perfect\", \"worth\", \"pictur\", \"expect\", \"price\", \"good\", \"fast\", \"good qualiti\", \"describ\", \"veri happi\", \"veri good\", \"great product\", \"work great\", \"deliveri\", \"wast\", \"great qualiti\", \"great price\", \"charg\", \"servic\", \"fast ship\", \"balloon\", \"veri pleas\", \"wast money\", \"good price\", \"rc\", \"happi purchas\", \"good product\", \"remot\", \"charger\", \"crash\", \"helicopt\", \"recommend anyon\", \"great item\", \"prompt\", \"veri veri\", \"boat\", \"batteri\", \"ship\", \"seller\", \"high qualiti\", \"fli\", \"deliv\", \"product\", \"qualiti\", \"excel\", \"thank\", \"item\", \"good\", \"price\", \"great\", \"happi\", \"veri\", \"would recommend\", \"work\", \"pleas\", \"recommend\", \"expect\", \"high\", \"exact\", \"quick\", \"purchas\", \"buy\", \"would\", \"receiv\", \"time\", \"came\", \"well\"], \"Total\": [36214.0, 33386.0, 20861.0, 15170.0, 14892.0, 12224.0, 12599.0, 11134.0, 16900.0, 10872.0, 18933.0, 12437.0, 9161.0, 13204.0, 11858.0, 10543.0, 11879.0, 9785.0, 7378.0, 7223.0, 8841.0, 10875.0, 13066.0, 5157.0, 10096.0, 5925.0, 16301.0, 10735.0, 5731.0, 23306.0, 8225.86439525578, 6352.726688856513, 6007.469025009549, 2440.9369112078825, 2266.563716782881, 2113.1477560841986, 2113.075412017884, 2073.575339120964, 2021.776794803093, 1881.399676936302, 1854.6945297007585, 2033.1346513592548, 1812.7968226064663, 1990.0899607367116, 1069.6212420586412, 1067.81332431221, 993.6855413987159, 988.2658773887767, 987.0597565885184, 1007.0230638179444, 946.4952570822588, 921.7716945699588, 969.5410219874917, 862.9639442984827, 851.3257545450574, 779.5488877934288, 750.9127243451279, 738.5575092627848, 732.4191929024779, 711.6076394585946, 10096.759889905952, 1683.6834058263291, 965.1441363891412, 2419.3806442445652, 1344.7793533412612, 5903.659420274649, 4255.202311758162, 3079.452274357848, 4205.877553064417, 3163.15100532035, 17079.42634833754, 16772.350046975804, 2371.541734866213, 3418.293021256028, 26489.156384602284, 8657.077870835672, 6973.507540008873, 4838.604679996467, 4036.7034702552487, 11094.03748890143, 4750.397622365641, 17190.574034738234, 23306.34160396312, 5815.004914227084, 7661.122204803781, 8273.48945428921, 5854.4576238270765, 13204.333894311367, 4072.7765408514656, 14092.25110454736, 5484.712477789269, 8224.216980512741, 11313.498434773323, 9846.743142095082, 13413.809872908738, 4149.651026579334, 16433.987680622482, 33386.570176482506, 11647.06523985718, 13722.341518692807, 10735.177445192807, 10393.343794964012, 8841.419090521693, 3628.1536213946993, 2228.1130740112776, 1819.2783869280643, 1816.4517601987693, 1609.5735887662363, 1256.861814888276, 1244.811970508264, 1154.0385209239964, 1088.3994436076614, 1052.6122060986995, 988.929714712129, 935.2734621387197, 855.6786629822678, 851.2659225968142, 828.7970137495178, 818.537333644083, 806.4690500202348, 801.7637677136986, 740.4457543688807, 720.1944472742031, 694.2383739972128, 688.4464706466142, 673.1082177520464, 666.9429019481712, 652.2971970896803, 637.5369006149315, 611.510345472453, 605.6930782214481, 605.6152701666883, 4026.6621451935994, 707.3368416022214, 747.5607035509279, 2090.6943761226876, 1643.6443513573474, 2697.4156039153454, 2298.632701430869, 13066.116389533852, 4311.064541119534, 1573.1620249173884, 3216.4828254875633, 1615.4544693395474, 2490.678515460025, 4521.536637791716, 7105.393156979878, 1593.3738123911298, 4019.2629612753476, 8064.99948347801, 6925.216363662621, 11094.03748890143, 11313.498434773323, 11102.491320798961, 17190.574034738234, 26489.156384602284, 5172.601664384717, 5273.868890781764, 16772.350046975804, 4210.439284764424, 3035.2484356536393, 23306.34160396312, 20861.230231510643, 6435.984514210088, 5981.886940527501, 5173.422083536126, 18933.674441323554, 16900.479862301007, 13722.341518692807, 8657.077870835672, 10872.97573989128, 9161.287554422128, 5731.260509171028, 4946.292519554815, 4278.054226165188, 3928.2764174220542, 3435.93548824661, 2614.465415763365, 2173.6059645270007, 2043.3338492426797, 1656.3937771091726, 1636.0044214317104, 1604.877492883492, 1368.3923518101737, 1262.638422959683, 1186.2690678145618, 1183.4808314816496, 1147.1340016397335, 1131.4224431846274, 1037.6477836398547, 1021.947961043555, 913.838391269916, 888.4219712472537, 820.6943036685007, 805.9248891766294, 732.1854689397776, 713.2614057721971, 692.6365931882615, 683.872481309203, 659.4888784235515, 15170.57841886497, 4614.63337360698, 2167.4700157180578, 14892.730364522671, 944.5780588084912, 3011.2483576653854, 11858.000338831309, 16900.479862301007, 10875.122555526566, 1726.3815419649675, 11879.716908916844, 4623.5396137879325, 3584.721649634811, 2531.4256551741496, 11647.06523985718, 11967.488906571782, 13413.809872908738, 36214.873431286214, 5173.422083536126, 13066.116389533852, 16433.987680622482, 14092.25110454736, 10393.343794964012, 11102.491320798961, 17190.574034738234, 3495.8362183464865, 6624.9663702366315, 7223.675967293426, 3299.7151559503377, 3112.927393830511, 2344.6133024127594, 2284.664322566825, 1934.9202651445012, 1757.47066645913, 1731.4831753527667, 1453.1720859270513, 1315.8185433417002, 1190.0582337002277, 1091.2251102749094, 974.9948929356789, 906.3693836559052, 866.3564965102645, 853.7696668769916, 797.6242298968524, 748.6636364535138, 741.0168125869111, 739.2431930603078, 686.0201688356007, 678.7381907034492, 678.3252059573032, 669.6235751949839, 636.6326032007986, 621.388807543668, 608.045689017932, 605.9205735460247, 591.1654009342486, 584.3605990805789, 11134.40801069793, 775.4297273162329, 795.0360389383221, 1905.9317852012273, 12437.367839838915, 9785.912978689792, 5136.896169835537, 18933.674441323554, 5053.238482579288, 8047.622383219317, 2788.2492661824103, 3552.170398415246, 1294.773244502799, 16301.143586385619, 10735.177445192807, 3866.385071063336, 7511.032953814304, 3036.7375440017927, 2685.2102761543315, 2271.4536812931365, 33386.570176482506, 23306.34160396312, 16433.987680622482, 13722.341518692807, 3613.144847584602, 8224.216980512741, 36214.873431286214, 11967.488906571782, 4298.011778854886, 5888.721673659293, 7730.7327887538495, 10543.268243963576, 20861.230231510643, 4306.577267135224, 2538.0403324419035, 2497.7947926635916, 2213.696774588855, 2186.416449419896, 1867.3356654221163, 1743.764174948874, 1535.565147033976, 1416.864623498687, 1402.3126254920614, 1360.3030956330524, 1331.538174084288, 1265.2889661738513, 1199.408135222446, 1107.7173898692643, 1067.9645276169783, 963.7385313826326, 821.3572157263103, 750.2255016862343, 734.9274789443609, 714.9840023038554, 614.983379597404, 583.5929459528344, 581.3835755636272, 569.4681481239705, 533.6089410741317, 530.1995018332989, 513.3952963568687, 510.2429648391038, 492.0776098485838, 4079.7706193025997, 5157.3495932752985, 2143.1736273943984, 1095.5325947935828, 2210.5551644467837, 934.1828831846558, 12224.54040953714, 12599.240845467053, 4251.5238543062715, 5925.058340427845, 7378.299003179343, 20861.230231510643, 10543.268243963576, 36214.873431286214, 6135.953588816783, 33386.570176482506, 2099.0939265345405, 13204.333894311367, 2454.0085297929168, 7747.074663476402, 7730.7327887538495, 5100.131826748833, 3830.3305914502835, 3707.287632208785, 8951.675683168573, 9846.743142095082, 17079.42634833754, 5181.4392943168305, 14092.25110454736, 6493.342233771735, 16301.143586385619], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.1122, 1.1122, 1.1122, 1.1122, 1.1122, 1.1122, 1.1122, 1.1122, 1.1122, 1.1122, 1.1122, 1.1122, 1.1122, 1.1122, 1.1121, 1.1121, 1.1121, 1.1121, 1.1121, 1.1121, 1.1121, 1.1121, 1.1121, 1.1121, 1.1121, 1.1121, 1.1121, 1.1121, 1.1121, 1.1121, 1.1118, 1.1096, 1.1078, 1.0549, 1.0612, 0.8889, 0.9276, 0.9633, 0.9112, 0.9437, 0.6992, 0.6903, 0.9781, 0.9151, 0.5703, 0.7575, 0.7937, 0.8457, 0.8781, 0.589, 0.8179, 0.3542, 0.2336, 0.7159, 0.6094, 0.5745, 0.7048, 0.2649, 0.8071, 0.2174, 0.666, 0.4545, 0.226, 0.3013, 0.1191, 0.7954, -0.1409, -0.6424, 0.0255, -0.1303, 0.0773, 0.0959, 1.4809, 1.4809, 1.4809, 1.4809, 1.4809, 1.4809, 1.4809, 1.4809, 1.4809, 1.4809, 1.4809, 1.4809, 1.4809, 1.4809, 1.4809, 1.4809, 1.4809, 1.4809, 1.4809, 1.4809, 1.4809, 1.4809, 1.4809, 1.4809, 1.4809, 1.4809, 1.4809, 1.4809, 1.4809, 1.4809, 1.4762, 1.4809, 1.4789, 1.4407, 1.4122, 1.3309, 1.3366, 1.072, 1.2078, 1.3524, 1.1958, 1.3178, 1.2165, 1.0387, 0.8927, 1.2808, 0.983, 0.7482, 0.7791, 0.582, 0.5576, 0.5585, 0.3857, 0.1339, 0.8243, 0.8102, 0.2381, 0.8801, 0.9965, -0.2203, -0.1751, 0.5501, 0.5642, 0.666, -0.35, -0.323, -0.2679, 0.1242, 1.7708, 1.7708, 1.7708, 1.7708, 1.7708, 1.7708, 1.7708, 1.7708, 1.7708, 1.7708, 1.7708, 1.7708, 1.7708, 1.7708, 1.7708, 1.7708, 1.7708, 1.7708, 1.7708, 1.7708, 1.7708, 1.7708, 1.7708, 1.7708, 1.7708, 1.7708, 1.7708, 1.7708, 1.7708, 1.7708, 1.7699, 1.7706, 1.7685, 1.7436, 1.7611, 1.7078, 1.5503, 1.4989, 1.5357, 1.6984, 1.4472, 1.4917, 1.5148, 1.5837, 1.1669, 1.0608, 1.0202, 0.4665, 1.1862, 0.6792, 0.4305, 0.4935, 0.5896, 0.4691, -0.0639, 1.3005, 0.6674, 1.8146, 1.8146, 1.8146, 1.8146, 1.8145, 1.8145, 1.8145, 1.8145, 1.8145, 1.8145, 1.8145, 1.8145, 1.8145, 1.8145, 1.8145, 1.8145, 1.8145, 1.8145, 1.8145, 1.8145, 1.8145, 1.8145, 1.8145, 1.8145, 1.8145, 1.8145, 1.8145, 1.8145, 1.8145, 1.8145, 1.814, 1.8142, 1.8132, 1.7709, 1.6382, 1.6297, 1.6278, 1.431, 1.5727, 1.4767, 1.6214, 1.5593, 1.7186, 1.2501, 1.3184, 1.5042, 1.3693, 1.5394, 1.5613, 1.5989, 0.9437, 0.8316, 0.9007, 0.9529, 1.4169, 1.0846, 0.1429, 0.7511, 1.2656, 1.0556, 0.6538, 0.3192, -0.3714, 2.2016, 2.2016, 2.2016, 2.2016, 2.2016, 2.2016, 2.2016, 2.2016, 2.2016, 2.2016, 2.2016, 2.2016, 2.2016, 2.2016, 2.2016, 2.2016, 2.2016, 2.2016, 2.2016, 2.2016, 2.2016, 2.2016, 2.2016, 2.2016, 2.2016, 2.2016, 2.2016, 2.2016, 2.2016, 2.2016, 2.2011, 2.1923, 2.1998, 2.1982, 2.1693, 2.1821, 2.0732, 2.0537, 2.0938, 2.0501, 1.9748, 1.7851, 1.7953, 1.5371, 1.817, 1.2817, 2.0101, 1.4492, 1.9618, 1.5852, 1.567, 1.608, 1.7255, 1.7022, 1.163, 1.0268, 0.6006, 1.3733, 0.571, 1.1679, 0.1973], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.6419, -4.9003, -4.9562, -5.8568, -5.9309, -6.001, -6.001, -6.0199, -6.0452, -6.1172, -6.1315, -6.0396, -6.1543, -6.061, -6.6819, -6.6836, -6.7555, -6.761, -6.7622, -6.7422, -6.8042, -6.8307, -6.7801, -6.8966, -6.9102, -6.9982, -7.0357, -7.0523, -7.0606, -7.0894, -4.4373, -6.2308, -6.789, -5.9229, -6.5039, -5.1968, -5.4856, -5.7733, -5.5136, -5.7661, -4.3242, -4.3513, -6.0197, -5.7171, -4.0143, -4.9455, -5.1255, -5.439, -5.5878, -4.866, -5.4852, -4.6628, -4.479, -5.385, -5.2157, -5.1738, -5.3894, -5.0159, -5.6499, -4.9983, -5.4933, -5.2998, -5.2093, -5.2729, -5.1459, -5.643, -5.2029, -4.9956, -5.3808, -5.3726, -5.4105, -5.4243, -4.201, -5.0917, -5.5793, -5.782, -5.7835, -5.9045, -6.1518, -6.1615, -6.2372, -6.2957, -6.3292, -6.3916, -6.4474, -6.5363, -6.5415, -6.5682, -6.5807, -6.5955, -6.6014, -6.681, -6.7087, -6.7454, -6.7538, -6.7763, -6.7855, -6.8077, -6.8306, -6.8723, -6.8818, -6.882, -4.9922, -6.7267, -6.6734, -5.6831, -5.9522, -5.5382, -5.6925, -4.2194, -5.1924, -6.0559, -5.4973, -6.0639, -5.7323, -5.3138, -5.0078, -6.1147, -5.4873, -5.0256, -5.1471, -4.8729, -4.8777, -4.8957, -4.6313, -4.4507, -5.3937, -5.3884, -4.8035, -5.5437, -5.7545, -4.9329, -4.9985, -5.4493, -5.5084, -5.5518, -5.2704, -5.357, -5.5103, -5.5787, -3.7042, -3.8755, -4.3446, -4.4919, -4.637, -4.7223, -4.8562, -5.1294, -5.3141, -5.3759, -5.5859, -5.5983, -5.6175, -5.7769, -5.8573, -5.9197, -5.9221, -5.9532, -5.967, -6.0536, -6.0688, -6.1806, -6.2088, -6.2881, -6.3063, -6.4022, -6.4284, -6.4578, -6.4705, -6.5068, -3.3721, -4.5615, -5.3193, -3.4169, -6.1572, -5.0512, -3.838, -3.5351, -3.9392, -5.6169, -3.9393, -4.8385, -5.0699, -5.3488, -4.2394, -4.3184, -4.2449, -3.8053, -5.0316, -4.6121, -4.6315, -4.7222, -4.9306, -4.9851, -5.0809, -5.3092, -5.3031, -4.0694, -4.8529, -4.9112, -5.1947, -5.2206, -5.3867, -5.4829, -5.4978, -5.673, -5.7723, -5.8728, -5.9595, -6.0721, -6.1451, -6.1903, -6.2049, -6.2729, -6.3363, -6.3465, -6.3489, -6.4237, -6.4343, -6.4349, -6.4478, -6.4984, -6.5226, -6.5443, -6.5478, -6.5725, -6.5841, -3.6373, -6.3015, -6.2775, -5.4454, -3.7024, -3.9507, -4.5971, -3.4894, -4.6686, -4.2992, -5.2145, -5.0344, -5.8844, -3.82, -4.1694, -5.0048, -4.4757, -5.2112, -5.3123, -5.442, -3.4095, -3.8811, -4.1613, -4.2894, -5.1598, -4.6696, -4.129, -4.628, -5.1376, -5.0327, -5.1624, -5.1867, -5.1949, -4.1996, -4.7283, -4.7443, -4.8651, -4.8775, -5.0352, -5.1037, -5.2308, -5.3113, -5.3216, -5.352, -5.3734, -5.4244, -5.4779, -5.5574, -5.594, -5.6967, -5.8566, -5.9471, -5.9677, -5.9953, -6.1459, -6.1983, -6.2021, -6.2228, -6.2879, -6.2943, -6.3265, -6.3326, -6.3689, -4.2542, -4.0287, -4.8993, -5.5719, -4.8987, -5.7473, -3.2847, -3.274, -4.3202, -4.032, -3.888, -3.0383, -3.7106, -2.7348, -4.2302, -3.0715, -5.1097, -3.8316, -5.0019, -4.2288, -4.2491, -4.624, -4.7929, -4.8489, -4.5065, -4.5474, -4.4229, -4.843, -4.6447, -4.8227, -4.8728]}, \"token.table\": {\"Topic\": [4, 3, 4, 1, 1, 4, 1, 2, 3, 4, 5, 1, 2, 3, 2, 4, 1, 2, 3, 4, 5, 1, 2, 1, 5, 2, 1, 2, 1, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 3, 3, 2, 2, 4, 1, 2, 5, 1, 1, 2, 3, 4, 5, 1, 2, 4, 1, 3, 4, 1, 1, 1, 2, 1, 1, 2, 3, 1, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 2, 4, 5, 2, 5, 5, 1, 3, 3, 1, 4, 2, 2, 4, 1, 2, 3, 4, 5, 2, 3, 1, 2, 4, 2, 3, 1, 2, 3, 4, 5, 3, 4, 2, 2, 1, 3, 4, 3, 1, 2, 3, 5, 2, 2, 5, 5, 5, 2, 4, 2, 1, 2, 3, 4, 1, 2, 4, 5, 4, 2, 3, 4, 1, 2, 4, 2, 2, 1, 3, 1, 2, 3, 4, 1, 2, 3, 4, 2, 3, 4, 5, 2, 4, 5, 1, 2, 4, 5, 1, 1, 3, 2, 4, 5, 5, 1, 2, 4, 4, 1, 1, 2, 3, 4, 1, 2, 4, 4, 2, 5, 1, 1, 2, 3, 1, 1, 2, 3, 2, 3, 1, 2, 1, 2, 3, 4, 3, 3, 4, 1, 2, 1, 2, 3, 4, 1, 2, 4, 5, 2, 5, 5, 5, 1, 2, 3, 4, 5, 3, 3, 3, 3, 3, 3, 2, 3, 4, 5, 4, 3, 5, 5, 5, 5, 3, 2, 2, 4, 1, 3, 4, 5, 5, 1, 2, 4, 5, 2, 3, 4, 5, 2, 5, 1, 2, 4, 1, 2, 1, 3, 5, 1, 3, 3, 2, 1, 2, 3, 5, 1, 2, 3, 4, 4, 2, 1, 2, 3, 4, 1, 2, 4, 5, 4, 1, 4, 1, 1, 2, 3, 4, 5, 3, 3, 3, 1, 2, 3, 4, 1, 2, 3, 4, 2, 2, 5, 2, 1, 3, 3, 1, 2, 5, 3, 1, 2, 4, 5, 3, 1, 3, 3, 3, 3, 1, 2, 3, 4, 1, 2, 4, 1, 1, 2, 3, 4, 1, 2, 3, 5, 2, 4, 1, 2, 4, 5, 3, 2, 3, 4, 5, 3, 1, 2, 4, 5, 1, 2, 4, 1, 2, 4, 1, 2, 3, 3, 2, 2, 4, 5, 4, 1, 2, 2, 3, 1, 2, 4, 5, 1, 2, 5, 5, 2, 1, 2, 3, 4, 5, 1, 1, 1, 1, 1, 2, 4, 5, 1, 2, 3, 5, 5, 4, 1, 2, 3, 4, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 2, 5, 1, 5, 2, 1, 2, 2, 4, 2, 5, 5, 1, 2, 3, 4, 2, 5, 4, 1, 3, 4, 2, 1, 4, 1, 4, 4, 1, 4, 1, 2, 4, 1, 2, 4, 1, 1, 4, 4, 4, 2, 3, 5, 1, 2, 3, 4, 4, 1, 2, 1, 2, 3, 5, 1, 1, 2, 3, 5, 1, 3, 4, 5, 1, 4, 1, 4, 1, 2, 1, 2, 3, 1, 2, 3, 5, 1, 2, 3, 4, 5, 4, 5, 5, 4, 5, 5, 2, 4, 5, 2, 4, 5, 5, 1, 1, 2, 3, 4, 5, 4, 4, 1, 2, 4, 2, 1, 2, 1, 2, 5, 5, 1, 2, 4, 5, 4, 4, 1, 2, 4, 5, 1, 5, 1, 3, 3, 2, 3, 3], \"Freq\": [1.0002697836804755, 0.24071886009506538, 0.7593675668662391, 0.9997309657301138, 1.0004733972076472, 1.00057709391155, 0.2646322165126722, 0.39987382305641944, 0.03343426614184109, 0.2973977973316765, 0.004680797259857752, 1.0001120795176823, 0.44264704542234923, 0.5572713676649051, 1.0003755346856638, 1.0000052380421254, 0.9999337715486947, 0.5185011671141364, 0.09395658732940726, 0.21227228989236455, 0.17496031179653, 0.7998428879185453, 0.20004541521215627, 1.0001924866324687, 1.0002551283687702, 0.9993514809565442, 0.18137614522878726, 0.8183892504440782, 0.0004902236391765286, 0.9995660002809417, 1.0001379040136027, 0.03698545213983873, 0.08198872956873342, 0.049917428412509623, 0.7332430546604393, 0.0977657406213919, 0.7013914037270715, 0.257477180320758, 0.0004620496730744872, 0.040660371230554875, 0.07464055049157753, 0.6078228828364131, 0.1477882899733235, 0.13833382024439037, 0.03159783304143449, 0.999940860846046, 0.9997731814629058, 0.9997512952401665, 0.9332919245779652, 0.0663160493996077, 0.1344277403726361, 0.8657320496490156, 0.9998422812844346, 0.9999300777317757, 0.3373381979998404, 0.020348473638575254, 0.5466613150076314, 0.09109590941151201, 0.00463636108220702, 0.4929809872675801, 0.49572458385752854, 0.011263186000841021, 0.12325070632127094, 0.8291770274626529, 0.04740411781587344, 0.9997875640454277, 0.9999643117242977, 0.9972183571981987, 0.002375743554968907, 1.0001162260966454, 0.07772464942731486, 0.7520637078586985, 0.17037243154467416, 0.9999770970310681, 0.44451245826533364, 0.1542642047304185, 0.01360856052263073, 0.07880778332508542, 0.30893463514807973, 1.000050921336926, 0.2259237149661024, 0.2690448057571785, 0.07392186992755906, 0.07546190888438321, 0.355748999026378, 0.7449902684646471, 0.0006315260823379319, 0.049680051810583985, 0.20461445067748996, 0.9999525991792265, 1.0003468364067216, 1.0006974965170303, 0.0002167019390358113, 0.9998627467112333, 1.0000931982922718, 0.09113564904201642, 0.9082671463848416, 1.0000710720760286, 0.1703363219872155, 0.8296838906394427, 0.14755115638108082, 0.48059519506980614, 0.09770614388932075, 0.233849983978755, 0.040297584725925435, 0.616094543706534, 0.3838236061059423, 0.16744415890341188, 0.1608017459882352, 0.6719907732520398, 0.061104225937263716, 0.9388132974165463, 0.6729143066459655, 0.27239873798293107, 0.0003439378004834988, 0.054342172476392815, 0.9993402366703336, 0.0005388701396818946, 0.9994244857300205, 1.000109944554037, 0.9996876151273588, 0.04275813882793388, 0.7904278739030529, 0.16671076493557876, 1.0000187756008838, 0.6401429453627775, 0.005469748892305134, 0.2691116455014126, 0.08551040768303693, 0.9999492512240081, 0.019268175775858248, 0.9805360561492308, 1.0002831875722524, 1.000082155402442, 0.2149116855940828, 0.7850411203975383, 0.9996329990703253, 0.26030973412057495, 0.6424806946646305, 0.06612796134413926, 0.031184088794393428, 0.8179030313171157, 0.06419587745802943, 0.034475563820052846, 0.08345464069543826, 1.0000448570378906, 1.0000856116043249, 0.042498897719704096, 0.9575368930674072, 0.8615168424888886, 0.12437276693299824, 0.013963522136080743, 1.0002449167252232, 1.0005652354961712, 0.2435363583004971, 0.7563469315957713, 0.737089297654517, 0.17383718279127183, 0.08691859139563592, 0.0022097946964992183, 0.584154971938042, 0.24584548167224857, 0.08762928918996077, 0.08243196583110793, 0.13445314645935166, 0.02558525893789604, 0.21878007132609065, 0.6210952144209662, 0.10043457702054322, 0.0016464684757466102, 0.8977957388464016, 0.11926424379086853, 0.037253906954197544, 0.31329500917731407, 0.5300920510357692, 1.000204796455197, 0.0023068369867822866, 0.9974763130846608, 0.22521442112036896, 0.7747376086540693, 1.00009815982358, 0.9996597194812504, 1.0000417812375078, 0.16881409058076272, 0.8311948019273148, 0.9993829168476686, 1.000316456854994, 0.6653050120557242, 0.2700506351887292, 0.06371213594269196, 0.00085405007966075, 0.3180654398256636, 0.04127261881371106, 0.640657553972831, 1.0004492852732632, 0.03166625340359615, 0.9680826040527964, 1.0005991283436504, 0.06806665170916609, 0.15789231503027873, 0.774118682348098, 0.9996173561726305, 0.13923089499276553, 0.05861021927315084, 0.8020745259092629, 0.6643136905586426, 0.33567740170394084, 0.001337684010475645, 0.9979122718148312, 0.6557816864776926, 0.28857017570252136, 0.04996318331378365, 0.00560446209009029, 0.9999686120078188, 0.6247432269676013, 0.37530362352632457, 0.9994767463666057, 1.0007263883621824, 0.6048722205598452, 0.20114546652626702, 0.13118182599539155, 0.06278453562565506, 0.03738993296866161, 0.19088040138616733, 0.11236154215197795, 0.659357087158898, 1.0006352710247972, 0.999565090901412, 1.0000223749008272, 0.9999841088254635, 0.36196243232354525, 0.13893507503327998, 0.30692720869540385, 0.10881964671927954, 0.08341877427552198, 1.0002863662579422, 1.0001864655974355, 0.9999296339176061, 0.9997622684203391, 0.9999545459204635, 1.0001812819247968, 0.02617708996826199, 0.271352598225855, 0.18793383367509608, 0.5145123601040354, 0.9999706002293856, 0.999525032854983, 0.9996237230842182, 0.999777185221422, 0.9998202436614199, 0.9997770643390222, 1.0003724850168119, 0.999966620764127, 1.0001510505170184, 0.999720947128078, 0.01450467294312801, 0.16281087944027958, 0.1419502262187022, 0.680741785207255, 1.0000986778392655, 0.728494994069884, 0.17158069327745862, 0.09976742558548858, 0.9991779204411823, 0.21097493879602613, 0.07803719855094647, 0.15862335082340626, 0.5523386641156186, 0.0036511921407082087, 0.9967754544133409, 0.9503417767566552, 0.04982229972041933, 0.9995885106053911, 0.13939268366885307, 0.8608239666996724, 0.1902877613654597, 0.01274006379512337, 0.7970671827566015, 0.27652174081137393, 0.723502088972225, 0.9998219843488619, 0.9999576585198064, 0.8211700935365065, 0.0032179804164237874, 0.1372029832093415, 0.03832322132286511, 0.4153805073531488, 0.18243961545972406, 0.027975218551208863, 0.37419000151087806, 1.0003857294316671, 0.999418390550483, 0.2856275720307831, 0.051661228942082416, 0.26177456644150593, 0.40099823171769505, 0.15559578829401594, 0.16024359188188878, 0.6814313851219937, 0.0026936134429717627, 0.9997321910014701, 0.17573751599005843, 0.8245317331860088, 1.000354104730222, 0.2783410355536847, 0.29403922844825264, 0.3317752690601947, 0.09539671066698957, 0.0006037766497910731, 0.9998831857136639, 0.999746691313, 0.9997132753558183, 0.35528057356032827, 0.00018630339463048153, 0.03558394837442197, 0.6088394936524136, 0.41225090778858164, 0.3972246096916565, 0.1116365558612733, 0.07893226000325974, 0.9991654344423909, 0.9953653560888203, 0.004718548344732431, 0.9996566395547393, 0.009528063791099247, 0.9898599605197551, 0.9996335063553395, 0.3486084366164532, 0.5553528021350522, 0.09612416722205795, 1.0000763342479728, 0.0045829632711689786, 0.1569463913214359, 0.8383606671662971, 8.04028644064733e-05, 0.9999972974206839, 0.0009887559713179523, 0.999039033419659, 1.000339437298184, 1.0001768460721587, 0.9998366154200384, 0.5816342270890831, 0.25999317985088044, 0.07357727712057006, 0.0847516609213339, 0.5926606978368053, 0.4069753689328024, 0.0003605540367068017, 0.9994276598612651, 0.7912396893988444, 0.1397179664436281, 0.06886807565838407, 0.9997937086740492, 0.10760120117328781, 0.7676623009079339, 0.0016059880772132508, 0.12325958492611701, 0.7610649222959586, 0.2389201066640772, 0.44388665104888214, 0.5113892771801944, 0.007205336497162546, 0.037543595432583794, 0.999987324572733, 0.00601629970682172, 0.49158182187822475, 0.3452687553970465, 0.15709227012256713, 0.9992587010341705, 0.2669509763097953, 0.211590913792624, 0.46818310539828606, 0.05332226880488278, 0.9996276142102071, 0.0002971250215625306, 9.904167385417686e-05, 0.7661299579453775, 0.20191771484020335, 0.031827357303368796, 0.07342986767897829, 0.1646698805403679, 0.7618718583678681, 1.0005246716897611, 0.9998469794782016, 0.12061897764673954, 0.09250171596557391, 0.786875830526534, 0.9998815791132256, 0.12077586223833332, 0.8791211446085, 0.06950954761912943, 0.9302694456360155, 0.04856179205087944, 0.06117647631409617, 0.22412405198482055, 0.6661122374479029, 0.12024991948598408, 0.00024540799895098796, 0.8794604655740238, 0.9992300351022423, 0.9997300072571526, 0.2732449305105079, 0.07339407986320674, 0.22800200456743525, 0.07149499408288024, 0.3539002207102572, 0.9999394600092654, 1.000016485166507, 1.000025846137943, 1.00004302265104, 0.007540136835639509, 0.00039684930713892156, 0.1296109837115718, 0.8625122841357321, 0.024546247560991812, 0.19259363470932037, 0.17613955667393025, 0.6069127144201272, 0.9996994214596445, 0.9994458204256366, 0.2886533609883021, 0.17394990474099395, 0.11492207782846563, 0.4224497686566996, 0.9995205751541486, 0.29181081049398966, 0.17002997622037358, 0.10113020152040382, 0.0003859931355740604, 0.4367512329020493, 0.0743506452462054, 0.1203034745997629, 0.12365958011434856, 0.14173091750057903, 0.5399457449043007, 1.0007328567716296, 1.000264921862995, 1.0000270257752444, 0.9444565928208768, 0.05538607590284354, 1.000294640760551, 1.0002476811030174, 0.9995237889751954, 1.0003684109865472, 0.9999773114636192, 0.0018663910141816515, 0.9980525948336381, 0.9997716204111657, 0.25255592812282585, 0.3975684260820803, 0.27201102101673824, 0.07791044145015846, 0.009307106127261086, 0.9906251084203518, 0.9996710242818726, 0.22018925784774968, 0.06647926238631269, 0.7133784025417217, 0.9997076126397361, 0.5181040347180075, 0.48199117428354415, 0.22381859824428058, 0.7761030927472224, 1.0005621438954064, 1.0005513720197046, 1.0000233240806171, 0.8450434378580324, 0.15427654233996252, 0.0009484213668440319, 0.3645700356146767, 0.548398835331784, 0.08692679676545387, 1.000110400513786, 1.000578683663892, 0.9999510665120591, 1.0001310839364812, 0.9995924579287804, 0.9993979918633464, 0.1405893329887195, 0.8594008206225205, 0.7273240863224975, 0.15444164845609815, 0.07786612359485727, 0.04043876031998113, 0.9999248592354865, 1.0001748205267156, 1.0005067282252145, 0.40873526573347346, 0.1167308180783965, 0.2788057046991002, 0.19578135384698842, 0.9999219263540775, 0.8745365807854955, 0.046804995403659594, 0.0767433257969914, 0.001686666501032778, 0.37043912557875625, 0.47205082374012564, 0.15618232402646293, 0.0013419006360268892, 0.9999547956431687, 1.000041208341726, 0.0012578046164239086, 0.9986968654405836, 0.8314528289815135, 0.16849962644989971, 0.4519899004693352, 0.39418988569635727, 0.15382261996034438, 0.46862891161869635, 0.33442745939621216, 0.15968053157811835, 0.037287876408587925, 0.17297374271969718, 0.009794357379972463, 0.00011980865296602403, 0.4185814813000464, 0.39854348409147894, 1.000146926368946, 0.9998095287748103, 1.0001369769403947, 1.0001649302197693, 1.0000332149449764, 0.9995238252051541, 0.007924440699910119, 0.8060917178630794, 0.18578410974233725, 0.9604464540264135, 0.039221418939325646, 1.0000955465321582, 1.0002713065928706, 1.0001647011377615, 0.1367388728396709, 0.1279664821639989, 0.031899602456989175, 0.5686717591851724, 0.13477582038077926, 1.0000863238298459, 0.9993742926506756, 0.0006190208507757163, 0.8492966072642828, 0.14980304588772336, 0.9998392268149574, 0.9957061994857623, 0.004144458686725337, 0.42857141036383406, 0.10019437637592375, 0.4712089265389248, 1.00013523907333, 0.3355039665303547, 0.08608631596132542, 0.5774763140973235, 0.000930662875257572, 1.0004711116952856, 0.9997202120861822, 0.6616732769306392, 0.07201647027915106, 0.06463917332372583, 0.20170466675745968, 0.17436094467875518, 0.8255943090936686, 0.026925888684270993, 0.9730922164899133, 1.0000022312299135, 0.9995443839234536, 0.9995937141786677, 0.9996266264761036], \"Term\": [\"action figur\", \"ador\", \"ador\", \"ago\", \"air\", \"american\", \"ani\", \"ani\", \"ani\", \"ani\", \"ani\", \"apart\", \"arriv\", \"arriv\", \"art\", \"articul\", \"away\", \"awesom\", \"awesom\", \"awesom\", \"awesom\", \"back\", \"back\", \"ball\", \"balloon\", \"band\", \"base\", \"base\", \"batteri\", \"batteri\", \"bear\", \"beauti\", \"beauti\", \"beauti\", \"beauti\", \"beauti\", \"becaus\", \"becaus\", \"becaus\", \"becaus\", \"best\", \"best\", \"best\", \"best\", \"best\", \"birthday\", \"birthday parti\", \"black\", \"blue\", \"blue\", \"board\", \"board\", \"boat\", \"book\", \"bought\", \"bought\", \"bought\", \"bought\", \"bought\", \"box\", \"box\", \"box\", \"boy\", \"boy\", \"boy\", \"break\", \"broke\", \"broken\", \"broken\", \"bubbl\", \"build\", \"build\", \"build\", \"button\", \"buy\", \"buy\", \"buy\", \"buy\", \"buy\", \"cake\", \"came\", \"came\", \"came\", \"came\", \"came\", \"car\", \"car\", \"car\", \"car\", \"card\", \"charg\", \"charger\", \"christma\", \"christma\", \"christma gift\", \"cloth\", \"cloth\", \"coin\", \"collect\", \"collect\", \"color\", \"color\", \"color\", \"color\", \"color\", \"condit\", \"condit\", \"cool\", \"cool\", \"cool\", \"costum\", \"costum\", \"could\", \"could\", \"could\", \"could\", \"crash\", \"cute\", \"cute\", \"damag\", \"dark\", \"daughter\", \"daughter\", \"daughter\", \"daughter love\", \"day\", \"day\", \"day\", \"day\", \"deck\", \"deliv\", \"deliv\", \"deliveri\", \"describ\", \"detail\", \"detail\", \"dice\", \"differ\", \"differ\", \"differ\", \"differ\", \"disappoint\", \"disappoint\", \"disappoint\", \"disappoint\", \"doll\", \"dragon\", \"dress\", \"dress\", \"easili\", \"easili\", \"easili\", \"effect\", \"engin\", \"enjoy\", \"enjoy\", \"enough\", \"enough\", \"enough\", \"enough\", \"even\", \"even\", \"even\", \"even\", \"exact\", \"exact\", \"exact\", \"exact\", \"excel\", \"excel\", \"excel\", \"expect\", \"expect\", \"expect\", \"expect\", \"fall\", \"famili\", \"famili\", \"fan\", \"fan\", \"fast\", \"fast ship\", \"fell\", \"figur\", \"figur\", \"figurin\", \"fill\", \"first\", \"first\", \"first\", \"first\", \"fit\", \"fit\", \"fit\", \"fit perfect\", \"fli\", \"fli\", \"floor\", \"friend\", \"friend\", \"friend\", \"frustrat\", \"fun\", \"fun\", \"fun\", \"game\", \"game\", \"gear\", \"gear\", \"get\", \"get\", \"get\", \"get\", \"gift\", \"girl\", \"girl\", \"given\", \"glow\", \"go\", \"go\", \"go\", \"go\", \"good\", \"good\", \"good\", \"good\", \"good condit\", \"good price\", \"good product\", \"good qualiti\", \"got\", \"got\", \"got\", \"got\", \"got\", \"grand\", \"grand daughter\", \"granddaught\", \"granddaught love\", \"grandson\", \"grandson love\", \"great\", \"great\", \"great\", \"great\", \"great addit\", \"great gift\", \"great item\", \"great price\", \"great product\", \"great qualiti\", \"great toy\", \"green\", \"gun\", \"hair\", \"happi\", \"happi\", \"happi\", \"happi\", \"happi purchas\", \"hard\", \"hard\", \"hard\", \"helicopt\", \"high\", \"high\", \"high\", \"high\", \"high qualiti\", \"high qualiti\", \"hole\", \"hole\", \"hors\", \"includ\", \"includ\", \"item\", \"item\", \"item\", \"kid\", \"kid\", \"kid love\", \"kit\", \"last\", \"last\", \"last\", \"last\", \"like\", \"like\", \"like\", \"like\", \"like pictur\", \"list\", \"littl\", \"littl\", \"littl\", \"littl\", \"look\", \"look\", \"look\", \"look\", \"look great\", \"look like\", \"look like\", \"lost\", \"lot\", \"lot\", \"lot\", \"lot\", \"lot\", \"lot fun\", \"love love\", \"love play\", \"made\", \"made\", \"made\", \"made\", \"make\", \"make\", \"make\", \"make\", \"mode\", \"model\", \"model\", \"mold\", \"month old\", \"month old\", \"much fun\", \"need\", \"need\", \"need\", \"nephew\", \"nice\", \"nice\", \"nice\", \"nice\", \"niec\", \"old\", \"old\", \"old daughter\", \"old grandson\", \"old love\", \"one\", \"one\", \"one\", \"one\", \"onli\", \"onli\", \"onli\", \"onli thing\", \"open\", \"open\", \"open\", \"outfit\", \"pack\", \"pack\", \"pack\", \"pack\", \"paint\", \"paint\", \"part\", \"part\", \"part\", \"part\", \"parti\", \"perfect\", \"perfect\", \"perfect\", \"perfect\", \"perfect condit\", \"pictur\", \"pictur\", \"pictur\", \"pictur\", \"piec\", \"piec\", \"piec\", \"plastic\", \"plastic\", \"plastic\", \"play\", \"play\", \"play\", \"play game\", \"player\", \"pleas\", \"pleas\", \"pleas\", \"plush\", \"point\", \"point\", \"present\", \"present\", \"price\", \"price\", \"price\", \"price\", \"product\", \"product\", \"product\", \"prompt\", \"protect\", \"purchas\", \"purchas\", \"purchas\", \"purchas\", \"purchas\", \"push\", \"put\", \"put togeth\", \"puzzl\", \"qualiti\", \"qualiti\", \"qualiti\", \"qualiti\", \"quick\", \"quick\", \"quick\", \"quick\", \"rc\", \"realist\", \"realli\", \"realli\", \"realli\", \"realli\", \"realli cute\", \"receiv\", \"receiv\", \"receiv\", \"receiv\", \"receiv\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"recommend anyon\", \"red\", \"remot\", \"return\", \"return\", \"ring\", \"rip\", \"rule\", \"satisfi\", \"sculpt\", \"seller\", \"seller\", \"servic\", \"set\", \"set\", \"set\", \"set\", \"ship\", \"ship\", \"shoe\", \"size\", \"size\", \"size\", \"sleev\", \"small\", \"small\", \"smaller\", \"smaller\", \"smaller expect\", \"smell\", \"soft\", \"someth\", \"someth\", \"someth\", \"star\", \"star\", \"star\", \"stay\", \"string\", \"stuf\", \"stuf anim\", \"super cute\", \"tail\", \"thank\", \"thank\", \"thing\", \"thing\", \"thing\", \"thing\", \"thoma\", \"thought would\", \"tile\", \"time\", \"time\", \"time\", \"time\", \"togeth\", \"took\", \"took\", \"took\", \"took\", \"toy\", \"toy\", \"toy\", \"toy\", \"track\", \"train\", \"transform\", \"transform\", \"tri\", \"tri\", \"two\", \"two\", \"two\", \"use\", \"use\", \"use\", \"use\", \"veri\", \"veri\", \"veri\", \"veri\", \"veri\", \"veri cute\", \"veri good\", \"veri happi\", \"veri nice\", \"veri pleas\", \"veri veri\", \"veri well\", \"veri well\", \"veri well\", \"version\", \"version\", \"wast\", \"wast money\", \"water\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well made\", \"well worth\", \"white\", \"white\", \"white\", \"wife\", \"wood\", \"wood\", \"work\", \"work\", \"work\", \"work great\", \"worth\", \"worth\", \"worth\", \"worth\", \"worth money\", \"worth price\", \"would\", \"would\", \"would\", \"would\", \"would recommend\", \"would recommend\", \"year\", \"year\", \"year old\", \"yellow\", \"yr\", \"yr old\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 5, 4, 3, 1]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el6541137298428967441197014\", ldavis_el6541137298428967441197014_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el6541137298428967441197014\", ldavis_el6541137298428967441197014_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el6541137298428967441197014\", ldavis_el6541137298428967441197014_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "1      0.124092 -0.117158       1        1  32.884614\n",
       "4      0.119885 -0.159743       2        1  22.742888\n",
       "3      0.149049  0.311623       3        1  17.018974\n",
       "2     -0.025797 -0.074713       4        1  16.290978\n",
       "0     -0.367229  0.039990       5        1  11.062546, topic_info=     Category          Freq             Term         Total  loglift  logprob\n",
       "term                                                                        \n",
       "1260  Default  36214.000000            great  36214.000000  30.0000  30.0000\n",
       "3167  Default  33386.000000             veri  33386.000000  29.0000  29.0000\n",
       "1191  Default  20861.000000             good  20861.000000  28.0000  28.0000\n",
       "2012  Default  15170.000000              old  15170.000000  27.0000  27.0000\n",
       "3396  Default  14892.000000             year  14892.000000  26.0000  26.0000\n",
       "2310  Default  12224.000000          product  12224.000000  25.0000  25.0000\n",
       "2366  Default  12599.000000          qualiti  12599.000000  24.0000  24.0000\n",
       "605   Default  11134.000000             cute  11134.000000  23.0000  23.0000\n",
       "2210  Default  16900.000000             play  16900.000000  22.0000  22.0000\n",
       "3399  Default  10872.000000         year old  10872.000000  21.0000  21.0000\n",
       "1670  Default  18933.000000             look  18933.000000  20.0000  20.0000\n",
       "1960  Default  12437.000000             nice  12437.000000  19.0000  19.0000\n",
       "1144  Default   9161.000000             gift   9161.000000  18.0000  18.0000\n",
       "3328  Default  13204.000000             work  13204.000000  17.0000  17.0000\n",
       "1067  Default  11858.000000              fun  11858.000000  16.0000  16.0000\n",
       "2289  Default  10543.000000            price  10543.000000  15.0000  15.0000\n",
       "1514  Default  11879.000000              kid  11879.000000  14.0000  14.0000\n",
       "968   Default   9785.000000            figur   9785.000000  13.0000  13.0000\n",
       "1481  Default   7378.000000             item   7378.000000  12.0000  12.0000\n",
       "731   Default   7223.000000             doll   7223.000000  11.0000  11.0000\n",
       "386   Default   8841.000000             card   8841.000000  10.0000  10.0000\n",
       "635   Default  10875.000000         daughter  10875.000000   9.0000   9.0000\n",
       "1090  Default  13066.000000             game  13066.000000   8.0000   8.0000\n",
       "2643  Default   5157.000000             ship   5157.000000   7.0000   7.0000\n",
       "2186  Default  10096.000000             piec  10096.000000   6.0000   6.0000\n",
       "2948  Default   5925.000000            thank   5925.000000   5.0000   5.0000\n",
       "3268  Default  16301.000000             well  16301.000000   4.0000   4.0000\n",
       "1772  Default  10735.000000             made  10735.000000   3.0000   3.0000\n",
       "1250  Default   5731.000000         grandson   5731.000000   2.0000   2.0000\n",
       "1597  Default  23306.000000             like  23306.000000   1.0000   1.0000\n",
       "...       ...           ...              ...           ...      ...      ...\n",
       "2643   Topic5   5109.392252             ship   5157.349593   2.1923  -4.0287\n",
       "2604   Topic5   2139.308954           seller   2143.173627   2.1998  -4.8993\n",
       "1381   Topic5   1091.824906     high qualiti   1095.532595   2.1982  -5.5719\n",
       "1021   Topic5   2140.381434              fli   2210.555164   2.1693  -4.8987\n",
       "671    Topic5    916.178231            deliv    934.182883   2.1821  -5.7473\n",
       "2310   Topic5  10751.496878          product  12224.540410   2.0732  -3.2847\n",
       "2366   Topic5  10867.002539          qualiti  12599.240845   2.0537  -3.2740\n",
       "880    Topic5   3817.219839            excel   4251.523854   2.0938  -4.3202\n",
       "2948   Topic5   5092.208312            thank   5925.058340   2.0501  -4.0320\n",
       "1481   Topic5   5881.034224             item   7378.299003   1.9748  -3.8880\n",
       "1191   Topic5  13754.763238             good  20861.230232   1.7851  -3.0383\n",
       "2289   Topic5   7022.645613            price  10543.268244   1.7953  -3.7106\n",
       "1260   Topic5  18633.341608            great  36214.873431   1.5371  -2.7348\n",
       "1337   Topic5   4176.789612            happi   6135.953589   1.8170  -4.2302\n",
       "3167   Topic5  13306.151501             veri  33386.570176   1.2817  -3.0715\n",
       "3377   Topic5   1733.227608  would recommend   2099.093927   2.0101  -5.1097\n",
       "3328   Topic5   6222.282177             work  13204.333894   1.4492  -3.8316\n",
       "2233   Topic5   1930.673455            pleas   2454.008530   1.9618  -5.0019\n",
       "2459   Topic5   4182.577192        recommend   7747.074663   1.5852  -4.2288\n",
       "895    Topic5   4098.447072           expect   7730.732789   1.5670  -4.2491\n",
       "1379   Topic5   2817.093536             high   5100.131827   1.6080  -4.6240\n",
       "869    Topic5   2379.401266            exact   3830.330591   1.7255  -4.7929\n",
       "2384   Topic5   2249.882887            quick   3707.287632   1.7022  -4.8489\n",
       "2341   Topic5   3168.306771          purchas   8951.675683   1.1630  -4.5065\n",
       "358    Topic5   3041.518479              buy   9846.743142   1.0268  -4.5474\n",
       "3354   Topic5   3444.665877            would  17079.426348   0.6006  -4.4229\n",
       "2448   Topic5   2263.164210           receiv   5181.439294   1.3733  -4.8430\n",
       "2997   Topic5   2759.486981             time  14092.251105   0.5710  -4.6447\n",
       "369    Topic5   2309.582913             came   6493.342234   1.1679  -4.8227\n",
       "3268   Topic5   2196.655131             well  16301.143586   0.1973  -4.8728\n",
       "\n",
       "[351 rows x 6 columns], token_table=      Topic      Freq             Term\n",
       "term                                  \n",
       "21        4  1.000270     action figur\n",
       "34        3  0.240719             ador\n",
       "34        4  0.759368             ador\n",
       "48        1  0.999731              ago\n",
       "51        1  1.000473              air\n",
       "72        4  1.000577         american\n",
       "80        1  0.264632              ani\n",
       "80        2  0.399874              ani\n",
       "80        3  0.033434              ani\n",
       "80        4  0.297398              ani\n",
       "80        5  0.004681              ani\n",
       "104       1  1.000112            apart\n",
       "120       2  0.442647            arriv\n",
       "120       3  0.557271            arriv\n",
       "127       2  1.000376              art\n",
       "128       4  1.000005          articul\n",
       "151       1  0.999934             away\n",
       "152       2  0.518501           awesom\n",
       "152       3  0.093957           awesom\n",
       "152       4  0.212272           awesom\n",
       "152       5  0.174960           awesom\n",
       "165       1  0.799843             back\n",
       "165       2  0.200045             back\n",
       "174       1  1.000192             ball\n",
       "175       5  1.000255          balloon\n",
       "176       2  0.999351             band\n",
       "183       1  0.181376             base\n",
       "183       2  0.818389             base\n",
       "190       1  0.000490          batteri\n",
       "190       5  0.999566          batteri\n",
       "...     ...       ...              ...\n",
       "3276      4  1.000086        well made\n",
       "3279      4  0.999374       well worth\n",
       "3289      1  0.000619            white\n",
       "3289      2  0.849297            white\n",
       "3289      4  0.149803            white\n",
       "3295      2  0.999839             wife\n",
       "3324      1  0.995706             wood\n",
       "3324      2  0.004144             wood\n",
       "3328      1  0.428571             work\n",
       "3328      2  0.100194             work\n",
       "3328      5  0.471209             work\n",
       "3333      5  1.000135       work great\n",
       "3348      1  0.335504            worth\n",
       "3348      2  0.086086            worth\n",
       "3348      4  0.577476            worth\n",
       "3348      5  0.000931            worth\n",
       "3351      4  1.000471      worth money\n",
       "3352      4  0.999720      worth price\n",
       "3354      1  0.661673            would\n",
       "3354      2  0.072016            would\n",
       "3354      4  0.064639            would\n",
       "3354      5  0.201705            would\n",
       "3377      1  0.174361  would recommend\n",
       "3377      5  0.825594  would recommend\n",
       "3396      1  0.026926             year\n",
       "3396      3  0.973092             year\n",
       "3399      3  1.000002         year old\n",
       "3401      2  0.999544           yellow\n",
       "3414      3  0.999594               yr\n",
       "3415      3  0.999627           yr old\n",
       "\n",
       "[567 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[2, 5, 4, 3, 1])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.sklearn.prepare(lda, tf, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T23:23:55.625130Z",
     "start_time": "2018-11-07T23:23:55.341277Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T23:27:53.923770Z",
     "start_time": "2018-11-07T23:27:53.667624Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(ar, open('../data/ar.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T00:19:28.994161Z",
     "start_time": "2018-11-08T00:19:28.938200Z"
    }
   },
   "outputs": [],
   "source": [
    "ar.models['orig']['X_train'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines\n",
    "\n",
    "1. (CountVectorizer, TF-IDF) -> (LDA, PCA, NMF, Word2Vec) -> K-Means -> (Logistic Regression, Random Forest, Gradient Boost)\n",
    "2. Sampling due to imbalanced classes (SMOTE, SMOTE->Tomek, SMOTE-> ENN) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T21:31:33.287361Z",
     "start_time": "2018-11-09T21:29:45.061720Z"
    }
   },
   "outputs": [],
   "source": [
    "### First Pipeline to transform the data\n",
    "\n",
    "## Transform documents into count vectors\n",
    "cv = CountVectorizer(\n",
    "                     stop_words=set(stopwords.words()), \n",
    "                        tokenizer=english_corpus, \n",
    "                        min_df=100,\n",
    "                        max_df=0.2,\n",
    "                        ngram_range = (1,2)) \n",
    "          \n",
    "\n",
    "tf = cv.fit_transform(ar.X_train) # 1-2 minutes\n",
    "\n",
    "n_components = 5\n",
    "\n",
    "lda = LatentDirichletAllocation(learning_method='online',\n",
    "                                learning_decay=0.6,\n",
    "                                batch_size=256,\n",
    "                                learning_offset=1024,\n",
    "                                n_components=n_components,\n",
    "                                n_jobs=-1,\n",
    "                                topic_word_prior=0.005,)\n",
    "\n",
    "# lda.fit(tf)\n",
    "\n",
    "## transform documents into topic probabilities\n",
    "lda_tf = lda.fit_transform(tf) # 8-10 minutes\n",
    "\n",
    "## upsample the minority class\n",
    "sm = SMOTE()\n",
    "X_train_smote, y_train_smote = sm.fit_sample(lda_tf, ar.y_train) ## seconds\n",
    "\n",
    "### End first pipeline\n",
    "\n",
    "### Second pipeline to fit classification algorithm, perform CV, and tune parameters\n",
    "\n",
    "## fit the classifier and tune parameters\n",
    "def on_step(optim_result):\n",
    "    score = grid.best_score_\n",
    "    print(f'best score: {score:.3}')\n",
    "#     if score >= 0.98:\n",
    "#         print('Interrupting!') # could stop it early if you hit some goal\n",
    "#         return True\n",
    "\n",
    "xgb_pipeline = Pipeline([\n",
    "        ('log_transform', FunctionTransformer(np.log)), # move this to the first pipeline\n",
    "        ('xgb', XGBClassifier(n_jobs=-1))]\n",
    ")\n",
    "\n",
    "xgb_params = {\n",
    "    'xgb__n_estimators': Integer(100, 500),\n",
    "    'xgb__learning_rate': Real(0,1),\n",
    "    'xgb__max_depth': Integer(2, 5)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "grid = BayesSearchCV(xgb_pipeline, xgb_params, cv=3, n_jobs=-1, scoring='precision', n_iter=4) # 5 mins or 1+ mins per iteration\n",
    "grid.fit(X_train_smote, y_train_smote, callback=on_step) # add callback to print the score of each BayesSearch\n",
    "### End second pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-10T11:38:01.088910Z",
     "start_time": "2018-11-10T11:26:31.129951Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('cv', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.2, max_features=None, min_df=100,\n",
       "        ngram_range=(1, 2), preprocessor=None,\n",
       "        stop_words={'olin', '...rgs=None,\n",
       "          inverse_func=None, kw_args=None, pass_y='deprecated',\n",
       "          validate=True))])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_pipeline = Pipeline(\n",
    "    [\n",
    "        ('cv', CountVectorizer(\n",
    "                     stop_words=set(stopwords.words()), \n",
    "                        tokenizer=english_corpus, \n",
    "                        min_df=100,\n",
    "                        max_df=0.2,\n",
    "                        ngram_range = (1,2))),\n",
    "        ('lda', LatentDirichletAllocation(learning_method='online',\n",
    "                                learning_decay=0.6,\n",
    "                                batch_size=256,\n",
    "                                learning_offset=1024,\n",
    "                                n_components=5,\n",
    "                                n_jobs=-1,\n",
    "                                topic_word_prior=0.005,)),\n",
    "        ('log_transform', FunctionTransformer(np.log))\n",
    "    ]\n",
    ")\n",
    "\n",
    "first_pipeline.fit(ar.X_train) ## need to save and then load this data for the classification algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T21:08:26.220134Z",
     "start_time": "2018-11-11T20:57:22.604877Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best mean test score: 0.0208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best mean test score: 0.0209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best mean test score: 0.0212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best mean test score: 0.0212\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BayesSearchCV(cv=StratifiedKFold(n_splits=3, random_state=42, shuffle=False),\n",
       "       error_score='raise',\n",
       "       estimator=Pipeline(memory='../data/transform_memory/',\n",
       "     steps=[('smote', SMOTE(k=None, k_neighbors=5, kind='regular', m=None, m_neighbors=10,\n",
       "   n_jobs=-1, out_step=0.5, random_state=42, ratio='auto',\n",
       "   svm_estimator=None)), ('xgb', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1...ate=42, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1))]),\n",
       "       fit_params=None, iid=True, n_iter=4, n_jobs=-1, n_points=1,\n",
       "       optimizer_kwargs=None, pre_dispatch='2*n_jobs', random_state=None,\n",
       "       refit=True, return_train_score=False, scoring='precision',\n",
       "       search_spaces={'xgb__n_estimators': Integer(low=100, high=500), 'xgb__learning_rate': Real(low=0, high=1, prior='uniform', transform='identity'), 'xgb__max_depth': Integer(low=2, high=5)},\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_pipeline = imbPipeline(\n",
    "    [\n",
    "        ('smote', SMOTE(n_jobs=-1, random_state=42)),\n",
    "        ('xgb', XGBClassifier(n_jobs=-1, random_state=42))\n",
    "    ],\n",
    "    memory = '../data/transform_memory/'\n",
    ")\n",
    "\n",
    "xgb_params = {\n",
    "    'xgb__n_estimators': Integer(100, 500),\n",
    "    'xgb__learning_rate': Real(0,1),\n",
    "    'xgb__max_depth': Integer(2, 5)\n",
    "}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3, random_state=42)\n",
    "\n",
    "grid = BayesSearchCV(second_pipeline, xgb_params, cv=skf, n_jobs=-1, scoring='precision', n_iter=4) # 5 mins or 1+ mins per iteration (10-15 mins)\n",
    "\n",
    "def on_step(optim_result):\n",
    "    score = np.max(grid.cv_results_['mean_test_score'])\n",
    "    print(f'best mean test score: {score:.3}')\n",
    "    \n",
    "grid.fit(first_pipeline.transform(ar.X_train), ar.y_train, callback=on_step) # add callback to print the score of each BayesSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T22:54:33.001291Z",
     "start_time": "2018-11-11T22:51:21.999474Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best mean test score: 0.0529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best mean test score: 0.0529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best mean test score: 0.0529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best mean test score: 0.0529\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BayesSearchCV(cv=StratifiedKFold(n_splits=3, random_state=42, shuffle=False),\n",
       "       error_score='raise',\n",
       "       estimator=Pipeline(memory='../data/transform_memory/',\n",
       "     steps=[('xgb', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=-1, nthread=None, objective='binary:logistic',\n",
       "       random_state=42, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1))]),\n",
       "       fit_params=None, iid=True, n_iter=4, n_jobs=-1, n_points=1,\n",
       "       optimizer_kwargs=None, pre_dispatch='2*n_jobs', random_state=None,\n",
       "       refit=True, return_train_score=False, scoring='precision',\n",
       "       search_spaces={'xgb__n_estimators': Integer(low=100, high=500), 'xgb__learning_rate': Real(low=0, high=1, prior='uniform', transform='identity'), 'xgb__max_depth': Integer(low=2, high=5)},\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_pipeline = imbPipeline(\n",
    "    [\n",
    "#         ('smote', SMOTE(n_jobs=-1, random_state=42)),\n",
    "        ('xgb', XGBClassifier(n_jobs=-1, random_state=42))\n",
    "    ],\n",
    "    memory = '../data/transform_memory/'\n",
    ")\n",
    "\n",
    "xgb_params = {\n",
    "    'xgb__n_estimators': Integer(100, 500),\n",
    "    'xgb__learning_rate': Real(0,1),\n",
    "    'xgb__max_depth': Integer(2, 5)\n",
    "}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3, random_state=42)\n",
    "\n",
    "grid = BayesSearchCV(second_pipeline, xgb_params, cv=skf, n_jobs=-1, scoring='precision', n_iter=4) # 5 mins or 1+ mins per iteration (10-15 mins)\n",
    "\n",
    "def on_step(optim_result):\n",
    "    score = np.max(grid.cv_results_['mean_test_score'])\n",
    "    print(f'best mean test score: {score:.3}')\n",
    "    \n",
    "grid.fit(train, ar.y_train, callback=on_step) # add callback to print the score of each BayesSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-10T11:14:41.212021Z",
     "start_time": "2018-11-10T11:14:41.159354Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8619624562207286"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(grid.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_score(y_true, y_score, run_name):\n",
    "    # add it to the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T22:55:05.265208Z",
     "start_time": "2018-11-11T22:55:03.083755Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = grid.best_estimator_.predict(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T23:38:45.628363Z",
     "start_time": "2018-11-11T23:38:45.235240Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T23:05:50.292822Z",
     "start_time": "2018-11-11T23:05:50.032810Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mvp</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.114166</td>\n",
       "      <td>0.204936</td>\n",
       "      <td>0.990644</td>\n",
       "      <td>0.557083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Precision    Recall        F1  Accuracy       AUC\n",
       "mvp        1.0  0.114166  0.204936  0.990644  0.557083"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {\n",
    "    'Precision': precision_score(ar.y_train, y_pred),\n",
    "    'Recall': recall_score(ar.y_train, y_pred),\n",
    "    'F1': f1_score(ar.y_train, y_pred),\n",
    "    'Accuracy': accuracy_score(ar.y_train, y_pred),\n",
    "    'AUC': roc_auc_score(ar.y_train, y_pred)\n",
    "}\n",
    "\n",
    "# print(results)\n",
    "pd.DataFrame(results, index=['mvp'])\n",
    "\n",
    "# print()\n",
    "# print()\n",
    "# print()\n",
    "# print(confusion_matrix(ar.y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T21:46:29.238910Z",
     "start_time": "2018-11-11T21:46:29.157234Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T22:47:01.008099Z",
     "start_time": "2018-11-11T22:47:00.945117Z"
    }
   },
   "outputs": [],
   "source": [
    "def modelfit(alg, dtrain, predictors,useTrainCV=True, cv_folds=skf, early_stopping_rounds=200):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain, label=ar.y_train)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], folds=cv_folds,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds, verbose_eval=False)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain, ar.y_train,eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain)\n",
    "    dtrain_predprob = alg.predict_proba(dtrain)[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print( \"\\nModel Report\")\n",
    "    print( \"Accuracy : %.4g\" % metrics.accuracy_score(ar.y_train, dtrain_predictions))\n",
    "    print( \"Precision : %.4g\" % metrics.precision_score(ar.y_train, dtrain_predictions))\n",
    "    print( \"Recall : %.4g\" % metrics.recall_score(ar.y_train, dtrain_predictions))\n",
    "    print( \"F1 : %.4g\" % metrics.f1_score(ar.y_train, dtrain_predictions))\n",
    "    print( \"AUC Score (Train): %f\" % metrics.roc_auc_score(ar.y_train, dtrain_predictions))\n",
    "#     print( \"Confusion : %\" % metrics.confusion_matrix(ar.y_train, dtrain_predictions))\n",
    "    return dtrain_predictions\n",
    "                    \n",
    "#     feat_imp = pd.Series(alg.feature_importances_).sort_values(ascending=False)\n",
    "#     feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "#     plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T21:18:39.385794Z",
     "start_time": "2018-11-11T21:16:42.229817Z"
    }
   },
   "outputs": [],
   "source": [
    "#Choose all predictors except target & IDcols\n",
    "train = first_pipeline.transform(ar.X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T22:47:35.601609Z",
     "start_time": "2018-11-11T22:47:08.934670Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy : 0.9894\n",
      "Precision : 0\n",
      "Recall : 0\n",
      "F1 : 0\n",
      "AUC Score (Train): 0.500000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "predictors = list(range(5))#[x for x in train.columns ]#if x not in [target, IDcol]]\n",
    "xgb1 = XGBClassifier()\n",
    "\n",
    "# xgb.Booster().\n",
    "y_pred = modelfit(xgb1, train, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T22:31:46.147753Z",
     "start_time": "2018-11-11T22:31:46.057537Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.685839</td>\n",
       "      <td>-3.671707</td>\n",
       "      <td>-1.899364</td>\n",
       "      <td>-0.256183</td>\n",
       "      <td>-3.656351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.677156</td>\n",
       "      <td>-5.509579</td>\n",
       "      <td>-5.518017</td>\n",
       "      <td>-0.975887</td>\n",
       "      <td>-2.234733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.124171</td>\n",
       "      <td>-3.481459</td>\n",
       "      <td>-3.555348</td>\n",
       "      <td>-3.547277</td>\n",
       "      <td>-3.553153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.511858</td>\n",
       "      <td>-2.299795</td>\n",
       "      <td>-3.169957</td>\n",
       "      <td>-0.454756</td>\n",
       "      <td>-5.947355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.764688</td>\n",
       "      <td>-2.416728</td>\n",
       "      <td>-0.842491</td>\n",
       "      <td>-4.925669</td>\n",
       "      <td>-4.904442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-4.780676</td>\n",
       "      <td>-0.033469</td>\n",
       "      <td>-4.802473</td>\n",
       "      <td>-4.810707</td>\n",
       "      <td>-4.806932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-2.193650</td>\n",
       "      <td>-7.750641</td>\n",
       "      <td>-1.214079</td>\n",
       "      <td>-0.526549</td>\n",
       "      <td>-7.734193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-2.706587</td>\n",
       "      <td>-0.916535</td>\n",
       "      <td>-2.708050</td>\n",
       "      <td>-2.705834</td>\n",
       "      <td>-0.916661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.417107</td>\n",
       "      <td>-0.332536</td>\n",
       "      <td>-4.311998</td>\n",
       "      <td>-4.299865</td>\n",
       "      <td>-4.304618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-2.302420</td>\n",
       "      <td>-2.300384</td>\n",
       "      <td>-2.295843</td>\n",
       "      <td>-2.300025</td>\n",
       "      <td>-0.512777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-2.302574</td>\n",
       "      <td>-2.302585</td>\n",
       "      <td>-2.302585</td>\n",
       "      <td>-2.299161</td>\n",
       "      <td>-0.511399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-2.992886</td>\n",
       "      <td>-0.228799</td>\n",
       "      <td>-2.940796</td>\n",
       "      <td>-2.994261</td>\n",
       "      <td>-2.966723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.743166</td>\n",
       "      <td>-2.047260</td>\n",
       "      <td>-4.171100</td>\n",
       "      <td>-0.974428</td>\n",
       "      <td>-6.006657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-3.531175</td>\n",
       "      <td>-1.037753</td>\n",
       "      <td>-3.554731</td>\n",
       "      <td>-0.581060</td>\n",
       "      <td>-3.554860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-2.708050</td>\n",
       "      <td>-0.310155</td>\n",
       "      <td>-2.708050</td>\n",
       "      <td>-2.708050</td>\n",
       "      <td>-2.708050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-1.332955</td>\n",
       "      <td>-1.599471</td>\n",
       "      <td>-0.988633</td>\n",
       "      <td>-1.950419</td>\n",
       "      <td>-3.912008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-1.609438</td>\n",
       "      <td>-1.609438</td>\n",
       "      <td>-1.609438</td>\n",
       "      <td>-1.609438</td>\n",
       "      <td>-1.609438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-3.553894</td>\n",
       "      <td>-3.530992</td>\n",
       "      <td>-3.554204</td>\n",
       "      <td>-0.330650</td>\n",
       "      <td>-1.634499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.076112</td>\n",
       "      <td>-4.002567</td>\n",
       "      <td>-4.001812</td>\n",
       "      <td>-3.991078</td>\n",
       "      <td>-4.003251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-3.400803</td>\n",
       "      <td>-0.628609</td>\n",
       "      <td>-1.003654</td>\n",
       "      <td>-3.400519</td>\n",
       "      <td>-3.398406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-2.065772</td>\n",
       "      <td>-3.136424</td>\n",
       "      <td>-2.809546</td>\n",
       "      <td>-0.265334</td>\n",
       "      <td>-5.929429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-2.962859</td>\n",
       "      <td>-2.995732</td>\n",
       "      <td>-0.603537</td>\n",
       "      <td>-2.963037</td>\n",
       "      <td>-1.204662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-1.316535</td>\n",
       "      <td>-0.872163</td>\n",
       "      <td>-1.271598</td>\n",
       "      <td>-4.084708</td>\n",
       "      <td>-4.093549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-3.551318</td>\n",
       "      <td>-3.555348</td>\n",
       "      <td>-0.121584</td>\n",
       "      <td>-3.555101</td>\n",
       "      <td>-3.552719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-2.299558</td>\n",
       "      <td>-2.302585</td>\n",
       "      <td>-2.288298</td>\n",
       "      <td>-2.300938</td>\n",
       "      <td>-0.514009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-1.591467</td>\n",
       "      <td>-0.362818</td>\n",
       "      <td>-3.401197</td>\n",
       "      <td>-3.399434</td>\n",
       "      <td>-3.383308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.844682</td>\n",
       "      <td>-0.674159</td>\n",
       "      <td>-3.911977</td>\n",
       "      <td>-3.897843</td>\n",
       "      <td>-3.890520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-1.009932</td>\n",
       "      <td>-2.321512</td>\n",
       "      <td>-3.092904</td>\n",
       "      <td>-0.713073</td>\n",
       "      <td>-6.153777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-4.531552</td>\n",
       "      <td>-0.678540</td>\n",
       "      <td>-4.551629</td>\n",
       "      <td>-0.775446</td>\n",
       "      <td>-4.525428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-1.339847</td>\n",
       "      <td>-0.390527</td>\n",
       "      <td>-3.904019</td>\n",
       "      <td>-3.895216</td>\n",
       "      <td>-3.867306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158370</th>\n",
       "      <td>-3.806645</td>\n",
       "      <td>-0.093191</td>\n",
       "      <td>-3.804450</td>\n",
       "      <td>-3.806631</td>\n",
       "      <td>-3.804809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158371</th>\n",
       "      <td>-1.115165</td>\n",
       "      <td>-1.129402</td>\n",
       "      <td>-4.603868</td>\n",
       "      <td>-1.112525</td>\n",
       "      <td>-4.588172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158372</th>\n",
       "      <td>-0.842238</td>\n",
       "      <td>-0.790850</td>\n",
       "      <td>-4.547702</td>\n",
       "      <td>-2.357364</td>\n",
       "      <td>-4.553101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158373</th>\n",
       "      <td>-2.995568</td>\n",
       "      <td>-2.993633</td>\n",
       "      <td>-0.223740</td>\n",
       "      <td>-2.994643</td>\n",
       "      <td>-2.989564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158374</th>\n",
       "      <td>-1.088127</td>\n",
       "      <td>-1.024724</td>\n",
       "      <td>-4.377888</td>\n",
       "      <td>-4.365922</td>\n",
       "      <td>-1.276534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158375</th>\n",
       "      <td>-0.777734</td>\n",
       "      <td>-1.076635</td>\n",
       "      <td>-4.083032</td>\n",
       "      <td>-4.072658</td>\n",
       "      <td>-1.796216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158376</th>\n",
       "      <td>-3.997611</td>\n",
       "      <td>-0.993646</td>\n",
       "      <td>-4.000154</td>\n",
       "      <td>-3.973744</td>\n",
       "      <td>-0.554603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158377</th>\n",
       "      <td>-2.202161</td>\n",
       "      <td>-4.471641</td>\n",
       "      <td>-2.417240</td>\n",
       "      <td>-0.251695</td>\n",
       "      <td>-4.477818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158378</th>\n",
       "      <td>-4.722742</td>\n",
       "      <td>-0.478687</td>\n",
       "      <td>-2.673582</td>\n",
       "      <td>-1.603673</td>\n",
       "      <td>-2.289156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158379</th>\n",
       "      <td>-2.049255</td>\n",
       "      <td>-2.984229</td>\n",
       "      <td>-2.847418</td>\n",
       "      <td>-0.500950</td>\n",
       "      <td>-1.853790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158380</th>\n",
       "      <td>-3.989126</td>\n",
       "      <td>-2.109708</td>\n",
       "      <td>-0.692283</td>\n",
       "      <td>-1.075824</td>\n",
       "      <td>-3.975933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158381</th>\n",
       "      <td>-0.862043</td>\n",
       "      <td>-3.910663</td>\n",
       "      <td>-0.659009</td>\n",
       "      <td>-3.906369</td>\n",
       "      <td>-3.902234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158382</th>\n",
       "      <td>-1.305744</td>\n",
       "      <td>-0.966964</td>\n",
       "      <td>-4.239887</td>\n",
       "      <td>-1.356514</td>\n",
       "      <td>-2.566196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158383</th>\n",
       "      <td>-2.982878</td>\n",
       "      <td>-2.993016</td>\n",
       "      <td>-0.224904</td>\n",
       "      <td>-2.994899</td>\n",
       "      <td>-2.984148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158384</th>\n",
       "      <td>-1.676282</td>\n",
       "      <td>-3.115386</td>\n",
       "      <td>-2.422841</td>\n",
       "      <td>-0.703083</td>\n",
       "      <td>-1.688242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158385</th>\n",
       "      <td>-3.218463</td>\n",
       "      <td>-0.480715</td>\n",
       "      <td>-3.218876</td>\n",
       "      <td>-3.216727</td>\n",
       "      <td>-1.341106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158386</th>\n",
       "      <td>-2.693834</td>\n",
       "      <td>-2.691010</td>\n",
       "      <td>-2.693908</td>\n",
       "      <td>-0.878407</td>\n",
       "      <td>-0.963628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158387</th>\n",
       "      <td>-2.992826</td>\n",
       "      <td>-2.995732</td>\n",
       "      <td>-0.225202</td>\n",
       "      <td>-2.994534</td>\n",
       "      <td>-2.967347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158388</th>\n",
       "      <td>-1.054625</td>\n",
       "      <td>-1.204750</td>\n",
       "      <td>-1.940399</td>\n",
       "      <td>-4.419725</td>\n",
       "      <td>-1.628489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158389</th>\n",
       "      <td>-1.777026</td>\n",
       "      <td>-0.305046</td>\n",
       "      <td>-2.567468</td>\n",
       "      <td>-4.760220</td>\n",
       "      <td>-4.770398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158390</th>\n",
       "      <td>-0.741721</td>\n",
       "      <td>-2.708050</td>\n",
       "      <td>-2.708050</td>\n",
       "      <td>-1.127918</td>\n",
       "      <td>-2.708050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158391</th>\n",
       "      <td>-2.302585</td>\n",
       "      <td>-2.294754</td>\n",
       "      <td>-0.516096</td>\n",
       "      <td>-2.302584</td>\n",
       "      <td>-2.279182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158392</th>\n",
       "      <td>-0.867581</td>\n",
       "      <td>-4.070902</td>\n",
       "      <td>-4.092307</td>\n",
       "      <td>-4.079304</td>\n",
       "      <td>-0.636102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158393</th>\n",
       "      <td>-0.334482</td>\n",
       "      <td>-2.282814</td>\n",
       "      <td>-2.506000</td>\n",
       "      <td>-4.986519</td>\n",
       "      <td>-2.365831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158394</th>\n",
       "      <td>-3.555348</td>\n",
       "      <td>-3.551142</td>\n",
       "      <td>-0.895320</td>\n",
       "      <td>-3.547841</td>\n",
       "      <td>-0.682261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158395</th>\n",
       "      <td>-3.547481</td>\n",
       "      <td>-3.543614</td>\n",
       "      <td>-1.074380</td>\n",
       "      <td>-3.534113</td>\n",
       "      <td>-0.559316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158396</th>\n",
       "      <td>-4.293992</td>\n",
       "      <td>-4.309995</td>\n",
       "      <td>-4.308690</td>\n",
       "      <td>-0.706789</td>\n",
       "      <td>-0.763056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158397</th>\n",
       "      <td>-0.631037</td>\n",
       "      <td>-2.995608</td>\n",
       "      <td>-2.985193</td>\n",
       "      <td>-1.148338</td>\n",
       "      <td>-2.990536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158398</th>\n",
       "      <td>-3.183994</td>\n",
       "      <td>-3.213753</td>\n",
       "      <td>-3.215796</td>\n",
       "      <td>-3.210424</td>\n",
       "      <td>-0.176842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158399</th>\n",
       "      <td>-0.662620</td>\n",
       "      <td>-4.356617</td>\n",
       "      <td>-4.375473</td>\n",
       "      <td>-0.806642</td>\n",
       "      <td>-4.362791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158400 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4\n",
       "0      -3.685839 -3.671707 -1.899364 -0.256183 -3.656351\n",
       "1      -0.677156 -5.509579 -5.518017 -0.975887 -2.234733\n",
       "2      -0.124171 -3.481459 -3.555348 -3.547277 -3.553153\n",
       "3      -1.511858 -2.299795 -3.169957 -0.454756 -5.947355\n",
       "4      -0.764688 -2.416728 -0.842491 -4.925669 -4.904442\n",
       "5      -4.780676 -0.033469 -4.802473 -4.810707 -4.806932\n",
       "6      -2.193650 -7.750641 -1.214079 -0.526549 -7.734193\n",
       "7      -2.706587 -0.916535 -2.708050 -2.705834 -0.916661\n",
       "8      -1.417107 -0.332536 -4.311998 -4.299865 -4.304618\n",
       "9      -2.302420 -2.300384 -2.295843 -2.300025 -0.512777\n",
       "10     -2.302574 -2.302585 -2.302585 -2.299161 -0.511399\n",
       "11     -2.992886 -0.228799 -2.940796 -2.994261 -2.966723\n",
       "12     -0.743166 -2.047260 -4.171100 -0.974428 -6.006657\n",
       "13     -3.531175 -1.037753 -3.554731 -0.581060 -3.554860\n",
       "14     -2.708050 -0.310155 -2.708050 -2.708050 -2.708050\n",
       "15     -1.332955 -1.599471 -0.988633 -1.950419 -3.912008\n",
       "16     -1.609438 -1.609438 -1.609438 -1.609438 -1.609438\n",
       "17     -3.553894 -3.530992 -3.554204 -0.330650 -1.634499\n",
       "18     -0.076112 -4.002567 -4.001812 -3.991078 -4.003251\n",
       "19     -3.400803 -0.628609 -1.003654 -3.400519 -3.398406\n",
       "20     -2.065772 -3.136424 -2.809546 -0.265334 -5.929429\n",
       "21     -2.962859 -2.995732 -0.603537 -2.963037 -1.204662\n",
       "22     -1.316535 -0.872163 -1.271598 -4.084708 -4.093549\n",
       "23     -3.551318 -3.555348 -0.121584 -3.555101 -3.552719\n",
       "24     -2.299558 -2.302585 -2.288298 -2.300938 -0.514009\n",
       "25     -1.591467 -0.362818 -3.401197 -3.399434 -3.383308\n",
       "26     -0.844682 -0.674159 -3.911977 -3.897843 -3.890520\n",
       "27     -1.009932 -2.321512 -3.092904 -0.713073 -6.153777\n",
       "28     -4.531552 -0.678540 -4.551629 -0.775446 -4.525428\n",
       "29     -1.339847 -0.390527 -3.904019 -3.895216 -3.867306\n",
       "...          ...       ...       ...       ...       ...\n",
       "158370 -3.806645 -0.093191 -3.804450 -3.806631 -3.804809\n",
       "158371 -1.115165 -1.129402 -4.603868 -1.112525 -4.588172\n",
       "158372 -0.842238 -0.790850 -4.547702 -2.357364 -4.553101\n",
       "158373 -2.995568 -2.993633 -0.223740 -2.994643 -2.989564\n",
       "158374 -1.088127 -1.024724 -4.377888 -4.365922 -1.276534\n",
       "158375 -0.777734 -1.076635 -4.083032 -4.072658 -1.796216\n",
       "158376 -3.997611 -0.993646 -4.000154 -3.973744 -0.554603\n",
       "158377 -2.202161 -4.471641 -2.417240 -0.251695 -4.477818\n",
       "158378 -4.722742 -0.478687 -2.673582 -1.603673 -2.289156\n",
       "158379 -2.049255 -2.984229 -2.847418 -0.500950 -1.853790\n",
       "158380 -3.989126 -2.109708 -0.692283 -1.075824 -3.975933\n",
       "158381 -0.862043 -3.910663 -0.659009 -3.906369 -3.902234\n",
       "158382 -1.305744 -0.966964 -4.239887 -1.356514 -2.566196\n",
       "158383 -2.982878 -2.993016 -0.224904 -2.994899 -2.984148\n",
       "158384 -1.676282 -3.115386 -2.422841 -0.703083 -1.688242\n",
       "158385 -3.218463 -0.480715 -3.218876 -3.216727 -1.341106\n",
       "158386 -2.693834 -2.691010 -2.693908 -0.878407 -0.963628\n",
       "158387 -2.992826 -2.995732 -0.225202 -2.994534 -2.967347\n",
       "158388 -1.054625 -1.204750 -1.940399 -4.419725 -1.628489\n",
       "158389 -1.777026 -0.305046 -2.567468 -4.760220 -4.770398\n",
       "158390 -0.741721 -2.708050 -2.708050 -1.127918 -2.708050\n",
       "158391 -2.302585 -2.294754 -0.516096 -2.302584 -2.279182\n",
       "158392 -0.867581 -4.070902 -4.092307 -4.079304 -0.636102\n",
       "158393 -0.334482 -2.282814 -2.506000 -4.986519 -2.365831\n",
       "158394 -3.555348 -3.551142 -0.895320 -3.547841 -0.682261\n",
       "158395 -3.547481 -3.543614 -1.074380 -3.534113 -0.559316\n",
       "158396 -4.293992 -4.309995 -4.308690 -0.706789 -0.763056\n",
       "158397 -0.631037 -2.995608 -2.985193 -1.148338 -2.990536\n",
       "158398 -3.183994 -3.213753 -3.215796 -3.210424 -0.176842\n",
       "158399 -0.662620 -4.356617 -4.375473 -0.806642 -4.362791\n",
       "\n",
       "[158400 rows x 5 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T21:42:32.561663Z",
     "start_time": "2018-11-11T21:42:32.489793Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.18633035, 0.2196908 , 0.184703  , 0.20748577, 0.20179008],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb1.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-11T20:55:06.194656Z",
     "start_time": "2018-11-11T20:55:06.099101Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_xgb__learning_rate</th>\n",
       "      <th>param_xgb__max_depth</th>\n",
       "      <th>param_xgb__n_estimators</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.020687</td>\n",
       "      <td>0.022606</td>\n",
       "      <td>0.021261</td>\n",
       "      <td>0.019686</td>\n",
       "      <td>0.021402</td>\n",
       "      <td>0.021128</td>\n",
       "      <td>0.000954</td>\n",
       "      <td>1</td>\n",
       "      <td>59.257421</td>\n",
       "      <td>14.880425</td>\n",
       "      <td>0.299999</td>\n",
       "      <td>0.057451</td>\n",
       "      <td>0.375366</td>\n",
       "      <td>3</td>\n",
       "      <td>228</td>\n",
       "      <td>{'xgb__learning_rate': 0.37536629600389537, 'x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.019941</td>\n",
       "      <td>0.022572</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.020158</td>\n",
       "      <td>0.020997</td>\n",
       "      <td>0.020989</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>1</td>\n",
       "      <td>47.640098</td>\n",
       "      <td>12.709890</td>\n",
       "      <td>0.281772</td>\n",
       "      <td>0.071071</td>\n",
       "      <td>0.355915</td>\n",
       "      <td>3</td>\n",
       "      <td>168</td>\n",
       "      <td>{'xgb__learning_rate': 0.355914821223876, 'xgb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.018401</td>\n",
       "      <td>0.024028</td>\n",
       "      <td>0.021701</td>\n",
       "      <td>0.020932</td>\n",
       "      <td>0.019840</td>\n",
       "      <td>0.020980</td>\n",
       "      <td>0.001885</td>\n",
       "      <td>1</td>\n",
       "      <td>124.678395</td>\n",
       "      <td>33.275390</td>\n",
       "      <td>0.822147</td>\n",
       "      <td>0.166377</td>\n",
       "      <td>0.873436</td>\n",
       "      <td>4</td>\n",
       "      <td>336</td>\n",
       "      <td>{'xgb__learning_rate': 0.8734364698987617, 'xg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.019352</td>\n",
       "      <td>0.023408</td>\n",
       "      <td>0.021597</td>\n",
       "      <td>0.019119</td>\n",
       "      <td>0.021209</td>\n",
       "      <td>0.020937</td>\n",
       "      <td>0.001577</td>\n",
       "      <td>1</td>\n",
       "      <td>41.672990</td>\n",
       "      <td>10.757350</td>\n",
       "      <td>0.235568</td>\n",
       "      <td>0.055358</td>\n",
       "      <td>0.614302</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>{'xgb__learning_rate': 0.6143015136800346, 'xg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.020370</td>\n",
       "      <td>0.022774</td>\n",
       "      <td>0.021680</td>\n",
       "      <td>0.018925</td>\n",
       "      <td>0.020650</td>\n",
       "      <td>0.020880</td>\n",
       "      <td>0.001293</td>\n",
       "      <td>1</td>\n",
       "      <td>38.170188</td>\n",
       "      <td>9.889327</td>\n",
       "      <td>0.201306</td>\n",
       "      <td>0.031854</td>\n",
       "      <td>0.411262</td>\n",
       "      <td>2</td>\n",
       "      <td>219</td>\n",
       "      <td>{'xgb__learning_rate': 0.4112619560466363, 'xg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.019419</td>\n",
       "      <td>0.022383</td>\n",
       "      <td>0.020841</td>\n",
       "      <td>0.018874</td>\n",
       "      <td>0.022571</td>\n",
       "      <td>0.020818</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1</td>\n",
       "      <td>77.505641</td>\n",
       "      <td>21.036156</td>\n",
       "      <td>0.383546</td>\n",
       "      <td>0.098243</td>\n",
       "      <td>0.459518</td>\n",
       "      <td>5</td>\n",
       "      <td>164</td>\n",
       "      <td>{'xgb__learning_rate': 0.4595177211741296, 'xg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.019091</td>\n",
       "      <td>0.022559</td>\n",
       "      <td>0.021022</td>\n",
       "      <td>0.018709</td>\n",
       "      <td>0.021424</td>\n",
       "      <td>0.020561</td>\n",
       "      <td>0.001452</td>\n",
       "      <td>1</td>\n",
       "      <td>38.537918</td>\n",
       "      <td>11.017908</td>\n",
       "      <td>0.164562</td>\n",
       "      <td>0.028528</td>\n",
       "      <td>0.593259</td>\n",
       "      <td>3</td>\n",
       "      <td>129</td>\n",
       "      <td>{'xgb__learning_rate': 0.5932591497765268, 'xg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.020309</td>\n",
       "      <td>0.021426</td>\n",
       "      <td>0.021162</td>\n",
       "      <td>0.019724</td>\n",
       "      <td>0.020123</td>\n",
       "      <td>0.020549</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>1</td>\n",
       "      <td>111.588964</td>\n",
       "      <td>28.793876</td>\n",
       "      <td>0.531416</td>\n",
       "      <td>0.115319</td>\n",
       "      <td>0.008854</td>\n",
       "      <td>3</td>\n",
       "      <td>386</td>\n",
       "      <td>{'xgb__learning_rate': 0.00885427240331327, 'x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.018437</td>\n",
       "      <td>0.023492</td>\n",
       "      <td>0.022667</td>\n",
       "      <td>0.019159</td>\n",
       "      <td>0.017807</td>\n",
       "      <td>0.020312</td>\n",
       "      <td>0.002314</td>\n",
       "      <td>1</td>\n",
       "      <td>149.401034</td>\n",
       "      <td>40.881506</td>\n",
       "      <td>0.860247</td>\n",
       "      <td>0.183763</td>\n",
       "      <td>0.594416</td>\n",
       "      <td>4</td>\n",
       "      <td>385</td>\n",
       "      <td>{'xgb__learning_rate': 0.5944155693385491, 'xg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.019038</td>\n",
       "      <td>0.020417</td>\n",
       "      <td>0.020592</td>\n",
       "      <td>0.018842</td>\n",
       "      <td>0.021876</td>\n",
       "      <td>0.020153</td>\n",
       "      <td>0.001113</td>\n",
       "      <td>1</td>\n",
       "      <td>49.375814</td>\n",
       "      <td>13.154031</td>\n",
       "      <td>0.268693</td>\n",
       "      <td>0.063447</td>\n",
       "      <td>0.942855</td>\n",
       "      <td>3</td>\n",
       "      <td>172</td>\n",
       "      <td>{'xgb__learning_rate': 0.9428553514329656, 'xg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "8           0.020687           0.022606           0.021261           0.019686   \n",
       "4           0.019941           0.022572           0.021277           0.020158   \n",
       "5           0.018401           0.024028           0.021701           0.020932   \n",
       "1           0.019352           0.023408           0.021597           0.019119   \n",
       "9           0.020370           0.022774           0.021680           0.018925   \n",
       "3           0.019419           0.022383           0.020841           0.018874   \n",
       "7           0.019091           0.022559           0.021022           0.018709   \n",
       "0           0.020309           0.021426           0.021162           0.019724   \n",
       "2           0.018437           0.023492           0.022667           0.019159   \n",
       "6           0.019038           0.020417           0.020592           0.018842   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "8           0.021402         0.021128        0.000954                1   \n",
       "4           0.020997         0.020989        0.000936                1   \n",
       "5           0.019840         0.020980        0.001885                1   \n",
       "1           0.021209         0.020937        0.001577                1   \n",
       "9           0.020650         0.020880        0.001293                1   \n",
       "3           0.022571         0.020818        0.001500                1   \n",
       "7           0.021424         0.020561        0.001452                1   \n",
       "0           0.020123         0.020549        0.000643                1   \n",
       "2           0.017807         0.020312        0.002314                1   \n",
       "6           0.021876         0.020153        0.001113                1   \n",
       "\n",
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "8      59.257421     14.880425         0.299999        0.057451   \n",
       "4      47.640098     12.709890         0.281772        0.071071   \n",
       "5     124.678395     33.275390         0.822147        0.166377   \n",
       "1      41.672990     10.757350         0.235568        0.055358   \n",
       "9      38.170188      9.889327         0.201306        0.031854   \n",
       "3      77.505641     21.036156         0.383546        0.098243   \n",
       "7      38.537918     11.017908         0.164562        0.028528   \n",
       "0     111.588964     28.793876         0.531416        0.115319   \n",
       "2     149.401034     40.881506         0.860247        0.183763   \n",
       "6      49.375814     13.154031         0.268693        0.063447   \n",
       "\n",
       "   param_xgb__learning_rate  param_xgb__max_depth  param_xgb__n_estimators  \\\n",
       "8                  0.375366                     3                      228   \n",
       "4                  0.355915                     3                      168   \n",
       "5                  0.873436                     4                      336   \n",
       "1                  0.614302                     3                      150   \n",
       "9                  0.411262                     2                      219   \n",
       "3                  0.459518                     5                      164   \n",
       "7                  0.593259                     3                      129   \n",
       "0                  0.008854                     3                      386   \n",
       "2                  0.594416                     4                      385   \n",
       "6                  0.942855                     3                      172   \n",
       "\n",
       "                                              params  \n",
       "8  {'xgb__learning_rate': 0.37536629600389537, 'x...  \n",
       "4  {'xgb__learning_rate': 0.355914821223876, 'xgb...  \n",
       "5  {'xgb__learning_rate': 0.8734364698987617, 'xg...  \n",
       "1  {'xgb__learning_rate': 0.6143015136800346, 'xg...  \n",
       "9  {'xgb__learning_rate': 0.4112619560466363, 'xg...  \n",
       "3  {'xgb__learning_rate': 0.4595177211741296, 'xg...  \n",
       "7  {'xgb__learning_rate': 0.5932591497765268, 'xg...  \n",
       "0  {'xgb__learning_rate': 0.00885427240331327, 'x...  \n",
       "2  {'xgb__learning_rate': 0.5944155693385491, 'xg...  \n",
       "6  {'xgb__learning_rate': 0.9428553514329656, 'xg...  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_).sort_values('mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is with bi-grams and 5 topics with SMOTE. Could look at the following,\n",
    "\n",
    "* tri-grams or single-grams or only bi-grams\n",
    "* tweak max/min df\n",
    "* Increasing the components for LDA.\n",
    "* Build a spaCy document vector matrix (a new notebook)\n",
    "* Experiment with sampling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
