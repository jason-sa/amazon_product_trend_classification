{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToDos\n",
    "\n",
    "* Review term frequency in major and minor classes\n",
    "* Pre-compute DTM and sampling for training data sets\n",
    "* LDA will take a long time...can I fit on something smaller and then partial fit\n",
    "* Figure out AWS\n",
    "* Use spaCy to transform documents into vectorized form. This will bypass count/tf-idf -> PCA/LDA pipeline\n",
    "\n",
    "\n",
    "## Fixed Data\n",
    "1. CountVectorizer\n",
    "2. tf-idf\n",
    "3. spaCy word embeddings\n",
    "4. Sampling\n",
    "\n",
    "Build out all of the above data structures, and then pickle the class. I can then reload the class to run the model pipelines with right training data sets. \n",
    "\n",
    "How do I maintain the test data?\n",
    "* Create models to transform the text later.\n",
    "* Transform and save the data\n",
    "\n",
    "\n",
    "### Pipelines\n",
    "1. Count/tf-idf -> PCA / LDA -> Supervised Learning\n",
    "  * stemming applied\n",
    "  * english words\n",
    "2. Word Embeddings -> Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T04:55:24.013076Z",
     "start_time": "2018-11-09T04:55:21.872281Z"
    }
   },
   "outputs": [],
   "source": [
    "import AmazonReviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T04:55:24.095965Z",
     "start_time": "2018-11-09T04:55:24.016143Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T04:56:38.248414Z",
     "start_time": "2018-11-09T04:55:24.098426Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read from pickle...\n"
     ]
    }
   ],
   "source": [
    "ar = AmazonReviews.AmazonReviews()\n",
    "\n",
    "PATH = '../data/amazon_reviews_us_Toys_v1_00.tsv'\n",
    "# ar.load_data(PATH)\n",
    "\n",
    "# ar.calc_trend_score()\n",
    "\n",
    "# ar.create_observations()\n",
    "\n",
    "# # ar.create_train_test_split(train_reduction=.1)\n",
    "# ar.create_train_test_split()\n",
    "# ar.dump_models()\n",
    "\n",
    "ar = ar.load_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the distribution of the first review data. 1/1/2014 is the most popular. May need to move the cutoff date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2014-01-01    0.030230\n",
    "2014-01-02    0.029510\n",
    "2014-01-03    0.026328\n",
    "2014-01-04    0.016026\n",
    "2014-01-07    0.014318"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T04:35:43.091405Z",
     "start_time": "2018-11-09T04:35:42.977040Z"
    }
   },
   "outputs": [],
   "source": [
    "# ar.reviews_selected_df.min_review_date.value_counts(normalize=True).sort_values(ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T04:35:43.148034Z",
     "start_time": "2018-11-09T04:35:43.094252Z"
    }
   },
   "outputs": [],
   "source": [
    "# ar.product_trend_df[ar.product_trend_df.trend == 1].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DTM / Sampling Creation\n",
    "\n",
    "Create DTM and only restrict features to English words in the `nltk.corpus.words`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T04:56:38.647993Z",
     "start_time": "2018-11-09T04:56:38.251515Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import words, stopwords\n",
    "from nltk import SnowballStemmer\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from imblearn.pipeline import Pipeline as imbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "\n",
    "# from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score, recall_score, precision_score, accuracy_score\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# skf = StratifiedKFold(n_splits = 10, random_state=ar.RANDOM_STATE)\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "def english_corpus(doc, tkpat=re.compile('\\\\b[a-z][a-z]+\\\\b')):\n",
    "    return [stemmer.stem(w) for w in tkpat.findall(doc)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T05:00:13.513695Z",
     "start_time": "2018-11-09T04:56:38.650684Z"
    }
   },
   "outputs": [],
   "source": [
    "## Create each pipe and add it to the data dictionary.\n",
    "pre_process_pipe = imbPipeline([\n",
    "                          ('cnt_v', CountVectorizer(\n",
    "                                        stop_words='english', \n",
    "                                        tokenizer=english_corpus, \n",
    "                                        min_df=2)),\n",
    "                          ('sm', SMOTE(random_state=42, n_jobs=-1))]) \n",
    "\n",
    "ar.pre_process_data(pre_process_pipe, 'cnt_v_1_gram_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T00:48:07.199126Z",
     "start_time": "2018-11-09T00:40:37.081943Z"
    }
   },
   "outputs": [],
   "source": [
    "pre_process_pipe = imbPipeline([\n",
    "                          ('cnt_v', CountVectorizer(\n",
    "                                        stop_words='english', \n",
    "                                        tokenizer=english_corpus, \n",
    "                                        min_df=2,\n",
    "                                        ngram_range = (1,2))),\n",
    "                          ('sm', SMOTE(random_state=42, n_jobs=-1))]) \n",
    "\n",
    "ar.pre_process_data(pre_process_pipe, 'cnt_v_2_gram_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T00:52:32.310716Z",
     "start_time": "2018-11-09T00:48:07.208272Z"
    }
   },
   "outputs": [],
   "source": [
    "pre_process_pipe = imbPipeline([\n",
    "                          ('cnt_v', TfidfVectorizer(\n",
    "                                        stop_words='english', \n",
    "                                        tokenizer=english_corpus, \n",
    "                                        min_df=2)),\n",
    "                          ('sm', SMOTE(random_state=42, n_jobs=-1))]) \n",
    "\n",
    "ar.pre_process_data(pre_process_pipe, 'tf_idf_1_gram_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T00:59:45.391994Z",
     "start_time": "2018-11-09T00:52:32.348671Z"
    }
   },
   "outputs": [],
   "source": [
    "pre_process_pipe = imbPipeline([\n",
    "                          ('cnt_v', TfidfVectorizer(\n",
    "                                        stop_words='english', \n",
    "                                        tokenizer=english_corpus, \n",
    "                                        min_df=2,\n",
    "                                        ngram_range = (1,2))),\n",
    "                          ('sm', SMOTE(random_state=42, n_jobs=-1))]) \n",
    "\n",
    "ar.pre_process_data(pre_process_pipe, 'tf_idf_2_gram_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-11-09T02:15:49.372Z"
    }
   },
   "outputs": [],
   "source": [
    "pre_process_pipe = imbPipeline([\n",
    "                          ('cnt_v', TfidfVectorizer(\n",
    "                                        stop_words='english', \n",
    "                                        tokenizer=english_corpus, \n",
    "                                        min_df=2,\n",
    "                                        ngram_range = (1,2))),\n",
    "                          ('sm', SMOTEENN(random_state=42, n_jobs=-1))]) \n",
    "\n",
    "ar.pre_process_data(pre_process_pipe, 'tf_idf_2_gram_sm_enn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-11-09T02:16:14.397Z"
    }
   },
   "outputs": [],
   "source": [
    "pre_process_pipe = imbPipeline([\n",
    "                          ('cnt_v', TfidfVectorizer(\n",
    "                                        stop_words='english', \n",
    "                                        tokenizer=english_corpus, \n",
    "                                        min_df=2)),\n",
    "                          ('sm', SMOTEENN(random_state=42, n_jobs=-1))]) \n",
    "\n",
    "ar.pre_process_data(pre_process_pipe, 'tf_idf_1_gram_sm_enn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-11-09T02:17:06.212Z"
    }
   },
   "outputs": [],
   "source": [
    "## Create each pipe and add it to the data dictionary.\n",
    "pre_process_pipe = imbPipeline([\n",
    "                          ('cnt_v', CountVectorizer(\n",
    "                                        stop_words='english', \n",
    "                                        tokenizer=english_corpus, \n",
    "                                        min_df=2)),\n",
    "                          ('sm', SMOTENN(random_state=42, n_jobs=-1))]) \n",
    "\n",
    "ar.pre_process_data(pre_process_pipe, 'cnt_v_1_gram_sm_enn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-11-09T02:17:07.472Z"
    }
   },
   "outputs": [],
   "source": [
    "pre_process_pipe = imbPipeline([\n",
    "                          ('cnt_v', CountVectorizer(\n",
    "                                        stop_words='english', \n",
    "                                        tokenizer=english_corpus, \n",
    "                                        min_df=2,\n",
    "                                        ngram_range = (1,2))),\n",
    "                          ('sm', SMOTENN(random_state=42, n_jobs=-1))]) \n",
    "\n",
    "ar.pre_process_data(pre_process_pipe, 'cnt_v_2_gram_sm_enn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T00:11:28.067883Z",
     "start_time": "2018-11-09T00:07:58.301679Z"
    }
   },
   "outputs": [],
   "source": [
    "X_temp, _ = pre_process_pipe.fit_sample(ar.X_train, ar.y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T00:11:28.264620Z",
     "start_time": "2018-11-09T00:11:28.072030Z"
    }
   },
   "outputs": [],
   "source": [
    "X_temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T00:11:28.350210Z",
     "start_time": "2018-11-09T00:11:28.268131Z"
    }
   },
   "outputs": [],
   "source": [
    "ar.X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "1. Create pipeline\n",
    "2. Pass it to a function to manage the data.\n",
    "  1. `fit_sample` pipeline\n",
    "  2. Save X_train, y_train, and model to a dictionary.\n",
    "  3. Write to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T21:46:55.285000Z",
     "start_time": "2018-11-08T21:46:55.158363Z"
    }
   },
   "outputs": [],
   "source": [
    "Xy_train = pd.concat([ar.y_train, ar.X_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T21:46:55.867162Z",
     "start_time": "2018-11-08T21:46:55.814109Z"
    }
   },
   "outputs": [],
   "source": [
    "Xy_train[Xy_train.trend==1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T21:47:03.367857Z",
     "start_time": "2018-11-08T21:47:01.535850Z"
    }
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(\n",
    "                                        stop_words='english', \n",
    "                                        tokenizer=english_corpus, \n",
    "                                        min_df=2)\n",
    "X_train_minor = cv.fit_transform(Xy_train.loc[Xy_train.trend==1, 'review_body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T21:47:15.205131Z",
     "start_time": "2018-11-08T21:47:06.581532Z"
    }
   },
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(         # could I fit on 1 of the 10 folds, and then partial fit\n",
    "                                        n_jobs=-1, \n",
    "                                        learning_method='online', \n",
    "                                        random_state=42)\n",
    "lda.fit(X_train_minor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T22:06:10.207549Z",
     "start_time": "2018-11-08T22:06:10.151738Z"
    }
   },
   "outputs": [],
   "source": [
    "ar.X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T23:00:09.080474Z",
     "start_time": "2018-11-08T23:00:09.021522Z"
    }
   },
   "outputs": [],
   "source": [
    "first_pipe = imbPipeline([\n",
    "                          ('lda', LatentDirichletAllocation(         # could I fit on 1 of the 10 folds, and then partial fit\n",
    "                                        n_jobs=-1, \n",
    "                                        learning_method='online',    \n",
    "                                        random_state=42)),\n",
    "                          ('log_transform', FunctionTransformer(np.log)),\n",
    "                          ('ss', StandardScaler()),\n",
    "                          ('log_reg', LogisticRegression(random_state=42))])\n",
    "\n",
    "params = {\n",
    "    'lda__n_components': Integer(5, 20),\n",
    "    'lda__learning_decay': Real(0.5, 1),\n",
    "    'log_reg__C': Categorical([0.001,0.01,0.1,1,10,100])\n",
    "}\n",
    "\n",
    "grid = BayesSearchCV(first_pipe, params, n_jobs=-1, n_iter=1, cv=1, scoring='precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T23:25:49.950467Z",
     "start_time": "2018-11-08T23:00:34.474407Z"
    }
   },
   "outputs": [],
   "source": [
    "ar.run_model(grid, 'mvp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T21:59:40.246520Z",
     "start_time": "2018-11-08T21:59:39.679388Z"
    }
   },
   "outputs": [],
   "source": [
    "second_pipe = imbPipeline([\n",
    "                          ('cnt_v', CountVectorizer(\n",
    "                                        stop_words='english', \n",
    "                                        tokenizer=english_corpus, \n",
    "                                        min_df=2)),\n",
    "                          ('sm', SMOTE(random_state=42, n_jobs=-1)),\n",
    "                          ('lda', LatentDirichletAllocation(\n",
    "                                        n_jobs=-1, \n",
    "                                        learning_method='online', \n",
    "                                        random_state=42)),\n",
    "                          ('log_transform', FunctionTransformer(np.log)),\n",
    "                          ('rf', RandomForestClassifier(n_jobs=-1, random_state=42))])\n",
    "\n",
    "params = {\n",
    "    'lda__n_components': Integer(5, 20),\n",
    "    'lda__learning_decay': Real(0.5, 1),\n",
    "    'rf__n_estimators': Integer(10,100),\n",
    "    'rf__max_depth': Integer(1,5)\n",
    "}\n",
    "\n",
    "second_grid = BayesSearchCV(second_pipe, params, n_jobs=-1, n_iter=5, cv=4, scoring='precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T22:01:16.730797Z",
     "start_time": "2018-11-08T21:59:42.369866Z"
    }
   },
   "outputs": [],
   "source": [
    "ar.run_model(second_grid, 'mvp_rf',t_func=english_corpus )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T23:37:53.413708Z",
     "start_time": "2018-11-08T23:37:53.208776Z"
    }
   },
   "outputs": [],
   "source": [
    "ar.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T23:46:00.065611Z",
     "start_time": "2018-11-08T23:45:59.846677Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(ar.models['mvp']['cv_results']).sort_values('mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T23:48:02.527637Z",
     "start_time": "2018-11-08T23:48:02.470450Z"
    }
   },
   "outputs": [],
   "source": [
    "ar.models['mvp']['best_model'].steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T19:34:11.197528Z",
     "start_time": "2018-11-08T19:34:10.966576Z"
    }
   },
   "outputs": [],
   "source": [
    "ar.conf_matrix('mvp_rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T19:42:29.180865Z",
     "start_time": "2018-11-08T19:42:28.921874Z"
    }
   },
   "outputs": [],
   "source": [
    "ar.dump_models(func=english_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T00:35:55.417962Z",
     "start_time": "2018-11-08T00:35:55.348668Z"
    }
   },
   "outputs": [],
   "source": [
    "features = ar.models['count_1_gram']['model'].get_feature_names()\n",
    "\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T00:35:55.495508Z",
     "start_time": "2018-11-08T00:35:55.420647Z"
    }
   },
   "outputs": [],
   "source": [
    "features.sort(reverse=True)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T00:32:17.065974Z",
     "start_time": "2018-11-08T00:32:17.013826Z"
    }
   },
   "outputs": [],
   "source": [
    "ar.models['count_1_gram']['X_train'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Running Framework\n",
    "\n",
    "1. Supervised model or pipeline is created\n",
    "2. BayesSearchCV is configured\n",
    "3. BayesSearchCV is fitted and scored and everything is logged.\n",
    "4. Data frame maintained reporting F1, precision, accuracy, and recall (rows), and models (columns)\n",
    "5. Perferably store the confusion matrix to plot heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T05:48:24.816053Z",
     "start_time": "2018-11-08T05:46:51.965015Z"
    }
   },
   "outputs": [],
   "source": [
    "grid.fit(ar.models['orig']['X_train'], ar.models['orig']['y_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T05:54:31.257335Z",
     "start_time": "2018-11-08T05:54:31.203663Z"
    }
   },
   "outputs": [],
   "source": [
    "print(grid.best_estimator_.named_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T05:51:23.903465Z",
     "start_time": "2018-11-08T05:51:21.462890Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = grid.predict(ar.models['orig']['X_train'])\n",
    "\n",
    "print('F1', f1_score(ar.models['orig']['y_train'], y_pred))\n",
    "print('Precision',precision_score(ar.models['orig']['y_train'], y_pred))\n",
    "print('Recall', recall_score(ar.models['orig']['y_train'], y_pred))\n",
    "print(confusion_matrix(ar.models['orig']['y_train'], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T06:05:57.976382Z",
     "start_time": "2018-11-08T06:05:57.917065Z"
    }
   },
   "outputs": [],
   "source": [
    "results = {\n",
    "    'F1': f1_score(ar.models['orig']['y_train'], y_pred),\n",
    "    'Precision': precision_score(ar.models['orig']['y_train'], y_pred),\n",
    "    'Recall': recall_score(ar.models['orig']['y_train'], y_pred),\n",
    "    'Accuracy': accuracy_score(ar.models['orig']['y_train'],y_pred)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T06:06:27.028538Z",
     "start_time": "2018-11-08T06:06:26.963376Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(data=results.values(), index=results.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|metric|score|\n",
    "---|---|\n",
    "|F1| 0.03751465416178194|\n",
    "|Precision| 0.01920768307322929|\n",
    "|Recall| 0.8|\n",
    "\n",
    "||Pred No| Pred Yes|\n",
    "|---|---|---|\n",
    "|Act No| 2425| 1634|\n",
    "|Act Yes|8|   32|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T05:43:15.927806Z",
     "start_time": "2018-11-08T05:43:15.740202Z"
    }
   },
   "outputs": [],
   "source": [
    "ar.models['orig']['X_train'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T03:52:06.755565Z",
     "start_time": "2018-11-08T03:52:06.663464Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T03:53:07.165899Z",
     "start_time": "2018-11-08T03:53:06.793450Z"
    }
   },
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=10)\n",
    "X_train_new = km.fit_transform(X_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T03:54:09.404149Z",
     "start_time": "2018-11-08T03:54:09.350705Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T22:41:40.211586Z",
     "start_time": "2018-11-07T22:41:40.114147Z"
    }
   },
   "outputs": [],
   "source": [
    "ar.models['count_1_gram']['X_train'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T22:06:24.678100Z",
     "start_time": "2018-11-07T22:06:24.586297Z"
    }
   },
   "outputs": [],
   "source": [
    "'he' in set(stopwords.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T21:26:08.150295Z",
     "start_time": "2018-11-08T21:26:07.823175Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T21:47:29.713374Z",
     "start_time": "2018-11-08T21:47:24.212879Z"
    }
   },
   "outputs": [],
   "source": [
    "pyLDAvis.sklearn.prepare(lda, X_train_minor, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T23:23:55.625130Z",
     "start_time": "2018-11-07T23:23:55.341277Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T23:27:53.923770Z",
     "start_time": "2018-11-07T23:27:53.667624Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(ar, open('../data/ar.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-08T00:19:28.994161Z",
     "start_time": "2018-11-08T00:19:28.938200Z"
    }
   },
   "outputs": [],
   "source": [
    "ar.models['orig']['X_train'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines\n",
    "\n",
    "1. (CountVectorizer, TF-IDF) -> (LDA, PCA, NMF, Word2Vec) -> K-Means -> (Logistic Regression, Random Forest, Gradient Boost)\n",
    "2. Sampling due to imbalanced classes (SMOTE, SMOTE->Tomek, SMOTE-> ENN) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
